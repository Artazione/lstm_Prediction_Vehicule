# ğŸš¦ PrÃ©diction de Flux VÃ©hicules avec ModÃ¨les LSTM

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9%2B-red.svg)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-orange.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Projet rÃ©alisÃ© dans le cadre de mon stage de M1 Informatique Parcours Intelligence Artificielle**  
> **Laboratoire CReSTIC - Lab-i*** - UniversitÃ© de Reims Champagne-Ardennes  
> **PÃ©riode :** Juillet 2025

## ğŸ“‹ Table des MatiÃ¨res

- [Ã€ Propos](#-Ã -propos)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Installation](#-installation)
- [Structure du Projet](#-structure-du-projet)
- [Guide d'Utilisation](#-guide-dutilisation)
- [Exemples DÃ©taillÃ©s](#-exemples-dÃ©taillÃ©s)
- [Architecture LSTM](#-architecture-lstm)
- [Datasets](#-datasets)
- [Remerciements](#-remerciements)
- [Licence](#-licence)

## ğŸ¯ Ã€ Propos

Ce projet dÃ©veloppe une solution complÃ¨te de **prÃ©diction de flux de vÃ©hicules** utilisant des modÃ¨les **LSTM (Long Short-Term Memory)** pour analyser et prÃ©voir le trafic routier. Le systÃ¨me comprend quatre composants principaux permettant l'optimisation d'hyperparamÃ¨tres, l'entraÃ®nement de modÃ¨les, l'Ã©valuation des performances et l'analyse de similaritÃ© entre modÃ¨les.

### Contexte AcadÃ©mique

Ce travail a Ã©tÃ© rÃ©alisÃ© dans le cadre de mon **stage de M1 Informatique Parcours Intelligence Artificielle** au sein du **Laboratoire CReSTIC - Lab-i*** de l'**UniversitÃ© de Reims Champagne-Ardennes**.

Le projet s'inscrit dans une dÃ©marche de recherche appliquÃ©e sur l'utilisation de l'intelligence artificielle pour l'optimisation du trafic urbain et la prÃ©diction des flux de vÃ©hicules en temps rÃ©el.

## âœ¨ FonctionnalitÃ©s

### ğŸš€ **Launcher UnifiÃ© (`main.py`)**
- Interface interactive pour tous les composants
- DÃ©tection automatique des dÃ©pendances
- Lancement direct en ligne de commande
- Diagnostic complet du systÃ¨me

### ğŸ”§ **Optimisation d'HyperparamÃ¨tres (`tuning_lstm.py`)**
- Optimisation bayÃ©sienne avec **Optuna**
- Validation croisÃ©e temporelle (TimeSeriesSplit)
- ParallÃ©lisation multi-GPU automatique
- Early stopping intelligent
- Sauvegarde automatique des modÃ¨les optimaux

### ğŸ§  **EntraÃ®nement et Ã‰valuation (`lstm.py`)**
- **Interface GUI** (Streamlit) et **CLI**
- EntraÃ®nement de modÃ¨les LSTM personnalisÃ©s
- Validation croisÃ©e optionnelle
- Visualisations interactives des prÃ©dictions
- Support multi-capteurs

### ğŸ“Š **Analyse de SimilaritÃ© (`analyse_similarite_lstm.py`)**
- Analyse de performance croisÃ©e entre modÃ¨les
- Clustering hiÃ©rarchique des modÃ¨les similaires
- Recommandations de consolidation
- Matrices de similaritÃ© interactives
- Interface Streamlit dÃ©diÃ©e

## ğŸ›  Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- CUDA (optionnel, pour l'accÃ©lÃ©ration GPU)

### Installation des DÃ©pendances

```bash
# Cloner le repository
git clone https://github.com/votre-username/lstm-traffic-prediction.git
cd lstm-traffic-prediction

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### DÃ©pendances Principales

Le fichier `requirements.txt` contient toutes les dÃ©pendances nÃ©cessaires :

```
# Core ML libraries
torch>=1.9.0
torchvision>=0.10.0
scikit-learn>=1.0.0
numpy>=1.21.0
pandas>=1.3.0

# Optimization
optuna>=3.0.0

# GUI and Visualization
streamlit>=1.28.0
plotly>=5.0.0
matplotlib>=3.5.0

# Data processing
scipy>=1.7.0
python-dateutil>=2.8.0

# CLI utilities
tabulate>=0.9.0

# Optional dependencies for enhanced functionality
seaborn>=0.11.0
```

## ğŸ“ Structure du Projet

```
lstm-traffic-prediction/
â”œâ”€â”€ main.py                        # ğŸš€ Launcher principal
â”œâ”€â”€ tuning_lstm.py                  # ğŸ”§ Optimisation d'hyperparamÃ¨tres
â”œâ”€â”€ lstm.py                         # ğŸ§  EntraÃ®nement et Ã©valuation
â”œâ”€â”€ analyse_similarite_lstm.py      # ğŸ“Š Analyse de similaritÃ©
â”œâ”€â”€ requirements.txt                # ğŸ“¦ DÃ©pendances Python
â”œâ”€â”€ README.md                       # ğŸ“– Documentation
â”œâ”€â”€ data/                           # ğŸ“‚ DonnÃ©es d'entrÃ©e
â”‚   â”œâ”€â”€ intersection1/
â”‚   â”‚   â””â”€â”€ traffic_data.csv
â”‚   â”œâ”€â”€ intersection2/
â”‚   â”‚   â””â”€â”€ traffic_data.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                         # ğŸ¤– ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ sensor_A12_Intersection1_bs64_hs128_nl2_do20_lr1e-3_ep50_ws24_mae125.pt
â”‚   â””â”€â”€ ...
â””â”€â”€ results/                        # ğŸ“ˆ RÃ©sultats et visualisations
    â”œâ”€â”€ predictions/
    â”œâ”€â”€ comparisons/
    â””â”€â”€ similarity_analysis/
```

## ğŸš€ Guide d'Utilisation

### DÃ©marrage Rapide

#### 1. Interface Interactive (RecommandÃ©)
```bash
python main.py
```

Cette commande lance l'interface interactive qui :
- Affiche le statut de tous les composants
- VÃ©rifie les dÃ©pendances automatiquement
- Propose une sÃ©lection guidÃ©e des fonctionnalitÃ©s

#### 2. VÃ©rification du SystÃ¨me
```bash
python main.py --status
```

Affiche un diagnostic complet avec les dÃ©pendances manquantes et les instructions d'installation.

#### 3. Aide Contextuelle
```bash
python main.py --help-component tuning
python main.py --help-component lstm
python main.py --help-component similarity
```

### Workflow Typique

1. **PrÃ©paration des donnÃ©es** : Placer les fichiers CSV dans `data/`
2. **Optimisation** : `tuning_lstm.py` pour trouver les meilleurs hyperparamÃ¨tres
3. **EntraÃ®nement** : `lstm.py` pour entraÃ®ner avec les paramÃ¨tres optimaux
4. **Analyse** : `analyse_similarite_lstm.py` pour analyser les similaritÃ©s

## ğŸ“˜ Exemples DÃ©taillÃ©s

### ğŸ”§ 1. Optimisation d'HyperparamÃ¨tres

#### Utilisation de Base
```bash
# Via le launcher
python main.py --component tuning --data ./data --trials 100

# Directement
python tuning_lstm.py --data ./data --trials 100
```

#### Configuration AvancÃ©e
```bash
# Optimisation intensive
python tuning_lstm.py \
    --data ./traffic_data \
    --trials 500 \
    --threshold 0.5
```

**FonctionnalitÃ©s :**
- **Optimisation multi-objectifs** : Minimise la MAE et la complexitÃ© du modÃ¨le
- **Validation croisÃ©e temporelle** : 5 folds avec TimeSeriesSplit
- **ParallÃ©lisation automatique** : Utilise tous les GPU disponibles
- **Early stopping** : ArrÃªt intelligent pour Ã©viter le surapprentissage

**Sortie :**
```
models/
â”œâ”€â”€ sensor_A12_Intersection1_bs64_hs128_nl2_do20_lr1e-3_ep50_ws24_mae125.pt
â”œâ”€â”€ sensor_B23_Intersection2_bs32_hs96_nl3_do30_lr5e-4_ep40_ws12_mae110.pt
â””â”€â”€ ...
```

### ğŸ§  2. EntraÃ®nement et Ã‰valuation

#### Mode GUI (Interface Streamlit)
```bash
# Via le launcher
python main.py --component lstm

# Directement
python lstm.py
```

**Interface Web :** Ouvre automatiquement dans le navigateur avec :
- Upload de fichiers CSV par glisser-dÃ©poser
- SÃ©lection interactive des capteurs
- Configuration des hyperparamÃ¨tres via sliders
- Visualisations en temps rÃ©el
- TÃ©lÃ©chargement des modÃ¨les entraÃ®nÃ©s

#### Mode CLI (Ligne de Commande)
```bash
# EntraÃ®nement en mode CLI
python main.py --component lstm --cli --data ./data --output ./results

# Mode verbeux
python lstm.py --cli --data ./data --output ./results --verbose

# Mode silencieux
python lstm.py --cli --data ./data --output ./results --quiet
```

**Workflow CLI :**
1. **DÃ©couverte automatique** des fichiers CSV
2. **SÃ©lection interactive** des fichiers et capteurs
3. **Configuration guidÃ©e** des hyperparamÃ¨tres
4. **EntraÃ®nement avec validation croisÃ©e** (optionnelle)
5. **GÃ©nÃ©ration automatique** des visualisations
6. **Sauvegarde structurÃ©e** des rÃ©sultats

#### Modes d'Utilisation Disponibles

##### **A. EntraÃ®ner Nouveau ModÃ¨le**
```bash
# Configuration interactive des hyperparamÃ¨tres
Enter hidden_size [64]: 128
Enter num_layers [2]: 3
Enter dropout [0.2]: 0.3
Enter learning_rate [0.0005]: 0.001
Enter epochs [20]: 50
Enter window_size [12]: 24
```

##### **B. Charger ModÃ¨le Existant**
```bash
# Ã‰valuation de modÃ¨les prÃ©-entraÃ®nÃ©s
python lstm.py --cli
# SÃ©lectionnez "Charger modÃ¨le existant"
# Choisissez les modÃ¨les .pt Ã  Ã©valuer
```

##### **C. Comparer Plusieurs ModÃ¨les**
```bash
# Comparaison de performances
python lstm.py --cli
# SÃ©lectionnez "Comparer plusieurs modÃ¨les"
# SÃ©lectionnez 2+ modÃ¨les pour le mÃªme capteur
```

### ğŸ“Š 3. Analyse de SimilaritÃ©

#### Interface Streamlit DÃ©diÃ©e
```bash
# Via le launcher
python main.py --component similarity

# Directement
streamlit run analyse_similarite_lstm.py
```

**FonctionnalitÃ©s de l'Interface :**

1. **Configuration Initiale**
   - SÃ©lection des dossiers de donnÃ©es et modÃ¨les
   - RÃ©glage du seuil de similaritÃ© (1-20% MAE)
   - DÃ©tection automatique du device (CPU/GPU)

2. **Analyse de Performance CroisÃ©e**
   - Matrice de performance interactive
   - Test de chaque modÃ¨le sur les donnÃ©es des autres capteurs
   - Calcul des diffÃ©rences relatives

3. **Visualisations AvancÃ©es**
   - **Heatmap interactive** : Matrice de performance avec Ã©chelle de couleurs
   - **Dendrogramme** : Clustering hiÃ©rarchique des modÃ¨les
   - **Tableaux rÃ©capitulatifs** : Performances dÃ©taillÃ©es par paire

4. **Recommandations Intelligentes**
   - Identification des modÃ¨les consolidables
   - Calcul du potentiel de rÃ©duction
   - StratÃ©gies de groupement optimales

#### Exemple de Sortie d'Analyse

```
ğŸ¯ ModÃ¨les similaires trouvÃ©s (seuil: 5.0% MAE):

Groupe 1: Peut utiliser un modÃ¨le commun
- A12 (Intersection_Centre) - MAE original: 12.5%
- A15 (Intersection_Centre) - MAE original: 11.8%
- B03 (Intersection_Centre) - MAE original: 13.2%

RÃ©duction potentielle: 2 modÃ¨les en moins (40% de rÃ©duction)
```

## ğŸ— Architecture LSTM

### ModÃ¨le Neural Network

```python
class RegresseurLSTM(nn.Module):
    def __init__(self, in_size=6, hid_size=64, n_layers=2, dropout=0.2):
        super().__init__()
        self.lstm = nn.LSTM(in_size, hid_size, n_layers, 
                           dropout=dropout, batch_first=True)
        self.fc = nn.Linear(hid_size, 1)
```

### Features d'EntrÃ©e (6 dimensions)

1. **`flow`** : Flux du capteur (variable cible)
2. **`hour_cos`** : Encodage cyclique de l'heure (cos(2Ï€Ã—heure/24))
3. **`mean_flow_others`** : Flux moyen des autres capteurs (contexte spatial)
4. **`ma3`** : Moyenne mobile sur 3 pÃ©riodes (tendance court terme)
5. **`ma6`** : Moyenne mobile sur 6 pÃ©riodes (tendance moyen terme)
6. **`ma12`** : Moyenne mobile sur 12 pÃ©riodes (tendance long terme)

### HyperparamÃ¨tres Optimisables

| ParamÃ¨tre | Plage | Description |
|-----------|-------|-------------|
| `hidden_size` | 64-128 | Taille des couches cachÃ©es LSTM |
| `num_layers` | 2-4 | Nombre de couches LSTM empilÃ©es |
| `dropout` | 0.3-0.5 | Taux de dropout pour rÃ©gularisation |
| `learning_rate` | 1e-4 Ã  1e-3 | Taux d'apprentissage Adam |
| `batch_size` | 16-128 | Taille des batchs d'entraÃ®nement |
| `window_size` | 12-24 | Longueur des sÃ©quences temporelles |
| `num_epochs` | 20-40 | Nombre d'Ã©poques d'entraÃ®nement |

## ğŸ“‚ Datasets

### Format des DonnÃ©es d'EntrÃ©e

Les donnÃ©es doivent Ãªtre organisÃ©es par intersection avec des fichiers CSV contenant :

```csv
count_point_name,measure_datetime,flow[veh/h]
A12,2025-07-01 00:00:00+02:00,145
A12,2025-07-01 01:00:00+02:00,89
A12,2025-07-01 02:00:00+02:00,67
A15,2025-07-01 00:00:00+02:00,203
A15,2025-07-01 01:00:00+02:00,156
...
```

### Structure RecommandÃ©e

```
data/
â”œâ”€â”€ intersection_centre/
â”‚   â””â”€â”€ traffic_2025.csv
â”œâ”€â”€ intersection_nord/
â”‚   â””â”€â”€ traffic_2025.csv
â”œâ”€â”€ intersection_sud/
â”‚   â””â”€â”€ traffic_2025.csv
â””â”€â”€ intersection_est/
    â””â”€â”€ traffic_2025.csv
```

### PrÃ©processing Automatique

- **Nettoyage des timestamps** : Conversion UTC â†’ Europe/Paris
- **Gestion des valeurs manquantes** : Imputation par moyenne
- **Validation des donnÃ©es** : VÃ©rification de cohÃ©rence
- **Feature engineering** : GÃ©nÃ©ration automatique des 6 features

## ğŸ“Š MÃ©triques et Ã‰valuation

### MÃ©triques Principales

- **MAE (Mean Absolute Error)** : Erreur absolue moyenne
- **MAE%** : MAE normalisÃ©e par le flux moyen (interprÃ©tation intuitive)
- **MSE (Mean Squared Error)** : Erreur quadratique moyenne

### Validation

- **Validation croisÃ©e temporelle** : TimeSeriesSplit (5 folds)
- **Division temporelle** : 80% entraÃ®nement / 20% test
- **Early stopping** : Patience de 10 Ã©poques

## ğŸ¤ Remerciements

Je tiens Ã  remercier chaleureusement l'Ã©quipe du **Laboratoire CReSTIC - Lab-i*** de l'**UniversitÃ© de Reims Champagne-Ardennes** pour leur encadrement et leur soutien tout au long de ce stage de M1 :

- **Monsieur Fouchal** - Directeur de stage et encadrant principal
- **Monsieur Rabat** - Co-encadrant et expert en intelligence artificielle  
- **Monsieur Ninet** - Conseiller technique et spÃ©cialiste des rÃ©seaux
- **Monsieur Keziou** - Expert en analyse de donnÃ©es et statistiques

Leur expertise, leurs conseils avisÃ©s et leur disponibilitÃ© ont Ã©tÃ© essentiels Ã  la rÃ©ussite de ce projet de recherche appliquÃ©e.

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ“ Support et Contact

- **Auteur :** Jules LefÃ¨vre
- **Email :** jules.lefevre@etudiant.univ-reims.fr
- **Institution :** UniversitÃ© de Reims Champagne-Ardennes
- **Laboratoire :** CReSTIC - Lab-i*

Pour toute question, suggestion ou contribution, n'hÃ©sitez pas Ã  ouvrir une issue ou Ã  me contacter directement.

---

**Fait avec â¤ï¸ dans le cadre du M1 Intelligence Artificielle - URCA 2025**