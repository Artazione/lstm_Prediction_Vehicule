"""
Script: analyse_similarite_lstm.py
Auteur: Jules Lef√®vre <jules.lefevre@etudiant.univ-reims.fr>
Date de cr√©ation: 21/07/2025
Description: Application Streamlit/CLI pour analyser la similarit√© entre mod√®les LSTM 
            entra√Æn√©s sur diff√©rents capteurs de trafic. L'outil permet d'identifier 
            les mod√®les qui peuvent √™tre consolid√©s en un seul mod√®le g√©n√©raliste,
            bas√© sur l'analyse des performances crois√©es (test d'un mod√®le sur les 
            donn√©es d'un autre capteur). Inclut visualisations interactives, 
            clustering hi√©rarchique et recommandations de consolidation.
            
Usage:
    # Mode GUI (Streamlit)
    python analyse_similarite_lstm.py
    
    # Mode CLI
    python analyse_similarite_lstm.py --cli --data ./data --models ./models --threshold 5.0 --output ./resultats
"""

import argparse
import sys
import os
import re
import glob
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Imports scientifiques
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# Imports pour la CLI
from tabulate import tabulate
from datetime import datetime

# Imports conditionnels pour Streamlit (seulement si mode GUI)
try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

# Imports pour les visualisations
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import squareform

# =============================================================================
# CONFIGURATION GLOBALE
# =============================================================================

# Variable globale pour contr√¥ler le mode d'ex√©cution
CLI_MODE = False
VERBOSE_LEVEL = 1  # 0: quiet, 1: normal, 2: verbose

def log_message(message, level=1):
    """Affiche un message selon le niveau de verbosit√©."""
    if not CLI_MODE:
        return  # En mode GUI, les messages sont g√©r√©s par Streamlit
    
    if VERBOSE_LEVEL >= level:
        print(message)

def log_error(message):
    """Affiche un message d'erreur."""
    if CLI_MODE:
        print(f"ERREUR: {message}", file=sys.stderr)
    else:
        st.error(message)

def log_success(message):
    """Affiche un message de succ√®s."""
    if CLI_MODE:
        log_message(f"‚úÖ {message}")
    else:
        st.success(message)

def log_info(message):
    """Affiche un message informatif."""
    if CLI_MODE:
        log_message(f"‚ÑπÔ∏è  {message}")
    else:
        st.info(message)

def log_warning(message):
    """Affiche un avertissement."""
    if CLI_MODE:
        log_message(f"‚ö†Ô∏è  {message}")
    else:
        st.warning(message)

# =============================================================================
# D√âFINITION DE L'ARCHITECTURE LSTM
# =============================================================================

class RegresseurLSTM(nn.Module):
    """
    Classe d√©finissant l'architecture du mod√®le LSTM pour la r√©gression.
    
    Architecture:
    - Couches LSTM empil√©es avec dropout
    - Couche lin√©aire finale pour la pr√©diction
    
    Args:
        in_size (int): Nombre de features d'entr√©e (6 dans notre cas)
        hid_size (int): Taille des couches cach√©es LSTM
        n_layers (int): Nombre de couches LSTM empil√©es
        dropout (float): Taux de dropout entre les couches LSTM
    """
    def __init__(self, in_size, hid_size, n_layers, dropout):
        super().__init__()
        # Couches LSTM empil√©es avec dropout et batch_first=True pour faciliter le traitement
        self.lstm = nn.LSTM(in_size, hid_size, n_layers,
                            dropout=dropout, batch_first=True)
        # Couche lin√©aire finale pour pr√©dire une seule valeur (flux de v√©hicules)
        self.fc = nn.Linear(hid_size, 1)

    def forward(self, x):
        """
        Propagation avant du mod√®le.
        
        Args:
            x (torch.Tensor): S√©quences d'entr√©e de forme (batch_size, seq_len, features)
            
        Returns:
            torch.Tensor: Pr√©dictions de forme (batch_size, 1)
        """
        # Passage dans les couches LSTM, on r√©cup√®re seulement les outputs
        out, _ = self.lstm(x)
        # On utilise seulement le dernier timestep pour la pr√©diction
        return self.fc(out[:, -1, :])

# =============================================================================
# FONCTIONS DE CHARGEMENT ET PR√âPARATION DES DONN√âES
# =============================================================================

def charger_donnees_selectif(dossier_racine, intersections_necessaires):
    """
    Charge s√©lectivement les donn√©es CSV des intersections n√©cessaires pour optimiser les performances.
    
    Cette fonction lit uniquement les donn√©es des intersections qui ont des mod√®les associ√©s,
    √©vitant ainsi de charger inutilement toutes les donn√©es disponibles.
    
    Args:
        dossier_racine (str): Chemin vers le dossier contenant les sous-dossiers d'intersections
        intersections_necessaires (set): Ensemble des noms d'intersections √† charger
        
    Returns:
        dict: Dictionnaire {nom_intersection: DataFrame_pivot} avec les donn√©es temporelles
              index√©es par datetime et colonnes = capteurs
    """
    donnees = {}
    
    # V√©rification de l'existence du dossier racine
    if not os.path.exists(dossier_racine):
        log_error(f"Dossier '{dossier_racine}' introuvable.")
        return donnees
    
    log_info(f"Chargement s√©lectif pour: {list(intersections_necessaires)}")
    
    # Parcours de tous les dossiers d'intersections
    for inter in sorted(os.listdir(dossier_racine)):
        # V√©rifier si cette intersection est n√©cessaire (optimisation performance)
        if not any(intersection in inter for intersection in intersections_necessaires):
            continue
            
        chemin = os.path.join(dossier_racine, inter)
        if not os.path.isdir(chemin):
            continue
            
        # Recherche du fichier CSV dans le dossier
        csvs = [f for f in os.listdir(chemin) if f.lower().endswith('.csv')]
        if not csvs:
            continue
            
        try:
            # Chargement optimis√©: seulement les colonnes n√©cessaires
            df = pd.read_csv(
                os.path.join(chemin, csvs[0]), sep=';', encoding='utf-8',
                usecols=['count_point_name', 'measure_datetime', 'flow[veh/h]']
            )
            
            # Conversion des dates avec gestion des erreurs
            df['measure_datetime'] = pd.to_datetime(
                df['measure_datetime'], utc=True, errors='coerce'
            )
            
            # Suppression des lignes avec des valeurs manquantes critiques
            df = df.dropna(subset=['measure_datetime', 'flow[veh/h]'])
            
            # Conversion du timezone UTC vers Europe/Paris
            df['measure_datetime'] = df['measure_datetime'].dt.tz_convert('Europe/Paris')
            
            # Cr√©ation du tableau pivot: lignes=datetime, colonnes=capteurs, valeurs=flux
            pivot = df.pivot(
                index='measure_datetime', columns='count_point_name', values='flow[veh/h]'
            ).sort_index()
            
            donnees[inter] = pivot
            log_success(f"{inter}: {pivot.shape[0]} lignes, {pivot.shape[1]} capteurs")
            
        except Exception as e:
            log_error(f"Erreur {inter}: {e}")
    
    return donnees

def creer_caracteristiques_selectif(donnees, capteurs_necessaires):
    """
    Cr√©e les caract√©ristiques d'entr√©e pour les mod√®les LSTM, uniquement pour les capteurs n√©cessaires.
    
    Pour chaque capteur, g√©n√®re:
    - flow: flux du capteur (variable cible)
    - mean_flow_others: flux moyen des autres capteurs de la m√™me intersection
    - hour_cos: encodage cyclique de l'heure (cosinus)
    - ma3, ma6, ma12: moyennes mobiles sur 3, 6 et 12 p√©riodes
    
    Args:
        donnees (dict): Donn√©es pivot par intersection
        capteurs_necessaires (dict): {intersection: set_of_capteurs} √† traiter
        
    Returns:
        dict: {(intersection, capteur): DataFrame_avec_features}
    """
    feats = {}
    
    for inter, pivot in donnees.items():
        # Identifier quels capteurs sont n√©cessaires pour cette intersection
        capteurs_inter = set()
        for intersection, capteurs in capteurs_necessaires.items():
            if intersection in inter:
                capteurs_inter.update(capteurs)
        
        if not capteurs_inter:
            continue
            
        # Remplissage des valeurs manquantes par la moyenne de chaque capteur
        filled = pivot.fillna(pivot.mean())
        
        # Calcul du flux total de l'intersection et du nombre de capteurs
        total = filled.sum(axis=1).values.reshape(-1, 1)
        count = filled.shape[1]
        
        # Calcul du flux moyen des "autres" capteurs pour chaque capteur
        # (total - capteur_actuel) / (nombre_capteurs - 1)
        others = (total - filled.values) / (count - 1)
        df_others = pd.DataFrame(others, index=filled.index, columns=filled.columns)
        
        # Traitement de chaque capteur individuellement
        for cap in pivot.columns:
            # V√©rifier si ce capteur est n√©cessaire (optimisation)
            if str(cap) not in capteurs_inter:
                continue
                
            # Cr√©ation du DataFrame de caract√©ristiques pour ce capteur
            dfc = pd.DataFrame(index=pivot.index)
            
            # Feature 1: flux du capteur (variable cible)
            dfc['flow'] = pivot[cap]
            
            # Feature 2: flux moyen des autres capteurs (contexte spatial)
            dfc['mean_flow_others'] = df_others[cap]
            
            # Feature 3: encodage cyclique de l'heure (contexte temporel)
            heures = dfc.index.hour
            dfc['hour_cos'] = np.cos(2 * np.pi * heures / 24)
            
            # Features 4-6: moyennes mobiles pour capturer les tendances
            for w in (3, 6, 12):
                dfc[f'ma{w}'] = dfc['flow'].rolling(window=w, min_periods=1).mean()
            
            # Suppression des lignes avec des valeurs manquantes dans 'flow'
            feats[(inter, cap)] = dfc.dropna(subset=['flow'])
            log_info(f"Caract√©ristiques cr√©√©es pour {inter} - capteur {cap}")
    
    return feats

# =============================================================================
# FONCTIONS DE PR√âPARATION DES S√âQUENCES ET PARSING
# =============================================================================

def creer_sequences(df, seq_len):
    """
    Transforme un DataFrame de caract√©ristiques en s√©quences pour l'entra√Ænement LSTM.
    
    Cr√©e des s√©quences glissantes de longueur seq_len, o√π chaque s√©quence X pr√©dit
    la valeur y au timestep suivant.
    
    Args:
        df (DataFrame): DataFrame avec les colonnes de caract√©ristiques
        seq_len (int): Longueur des s√©quences d'entr√©e
        
    Returns:
        tuple: (X, y) o√π X.shape = (n_sequences, seq_len, n_features)
               et y.shape = (n_sequences,)
    """
    # Colonnes de caract√©ristiques dans l'ordre attendu par le mod√®le
    cols = ['flow', 'hour_cos', 'mean_flow_others', 'ma3', 'ma6', 'ma12']
    arr = df[cols].values
    
    X, y = [], []
    # Cr√©ation des s√©quences glissantes
    for i in range(seq_len, len(arr)):
        # S√©quence d'entr√©e: timesteps [i-seq_len:i]
        X.append(arr[i-seq_len:i])
        # Valeur cible: flux au timestep i
        y.append(arr[i, 0])  # 0 = index de 'flow'
        
    return np.array(X), np.array(y)

def parser_nom_modele(nom_fichier):
    """
    Parse le nom d'un fichier de mod√®le pour extraire ses hyperparam√®tres.
    
    Format attendu: sensor_CAPTEUR_INTERSECTION_bs_hs_nl_do_lr_ep_ws_mae.pt
    Exemple: sensor_A12_Intersection1_bs32_hs64_nl2_do20_lr1e-3_ep100_ws24_mae150.pt
    
    Args:
        nom_fichier (str): Nom du fichier de mod√®le
        
    Returns:
        dict or None: Dictionnaire des param√®tres extraits ou None si parsing √©choue
    """
    # Expression r√©guli√®re pour extraire tous les param√®tres du nom de fichier
    pattern = r'sensor_(.+)_bs(\d+)_hs(\d+)_nl(\d+)_do(\d+)_lr(\d+e-\d+)_ep(\d+)_ws(\d+)_mae(\d+)\.pt'
    match = re.match(pattern, nom_fichier)
    
    if match:
        return {
            'capteur_inter': match.group(1),      # Identifiant capteur_intersection
            'batch_size': int(match.group(2)),    # Taille des batchs
            'hidden_size': int(match.group(3)),   # Taille des couches cach√©es
            'num_layers': int(match.group(4)),    # Nombre de couches LSTM
            'dropout': int(match.group(5)) / 100.0,  # Taux de dropout (converti en decimal)
            'learning_rate': float(match.group(6)),  # Taux d'apprentissage
            'num_epochs': int(match.group(7)),    # Nombre d'√©poques d'entra√Ænement
            'window_size': int(match.group(8)),   # Taille des s√©quences
            'mae_original': int(match.group(9))   # MAE original du mod√®le (en centi√®mes de %)
        }
    return None

def extraire_capteur_intersection(capteur_inter):
    """
    S√©pare l'identifiant capteur_intersection en capteur et intersection.
    
    Args:
        capteur_inter (str): Cha√Æne au format "capteur_intersection"
        
    Returns:
        tuple: (capteur, intersection)
    """
    parts = capteur_inter.split('_')
    if len(parts) >= 2:
        capteur = parts[0]  # Premier √©l√©ment = nom du capteur
        intersection = '_'.join(parts[1:])  # Reste = nom de l'intersection
        return capteur, intersection
    return capteur_inter, ""

# =============================================================================
# FONCTIONS DE CHARGEMENT ET √âVALUATION DES MOD√àLES
# =============================================================================

def charger_modele(chemin_modele, params, device):
    """
    Charge un mod√®le LSTM depuis un fichier .pt.
    
    Args:
        chemin_modele (str): Chemin vers le fichier .pt
        params (dict): Param√®tres du mod√®le pour reconstruire l'architecture
        device (torch.device): Device sur lequel charger le mod√®le
        
    Returns:
        RegresseurLSTM: Mod√®le charg√© et pr√™t pour l'√©valuation
    """
    # Reconstruction de l'architecture avec les param√®tres extraits
    model = RegresseurLSTM(6, params['hidden_size'], params['num_layers'], params['dropout'])
    
    # Chargement des poids sauvegard√©s
    model.load_state_dict(torch.load(chemin_modele, map_location=device))
    
    # D√©placement vers le device appropri√© et passage en mode √©valuation
    model.to(device)
    model.eval()
    
    return model

def evaluer_modele(model, X_test, y_test, device, mean_flow):
    """
    √âvalue un mod√®le sur un jeu de donn√©es de test.
    
    Calcule la MAE en pourcentage par rapport au flux moyen pour une interpr√©tation
    plus intuitive des performances.
    
    Args:
        model (RegresseurLSTM): Mod√®le √† √©valuer
        X_test (np.array): S√©quences de test
        y_test (np.array): Valeurs cibles de test
        device (torch.device): Device pour les calculs
        mean_flow (float): Flux moyen pour normaliser la MAE
        
    Returns:
        tuple: (mae_percentage, predictions)
    """
    model.eval()
    with torch.no_grad():
        # Conversion en tenseurs PyTorch
        X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
        y_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)
        
        # Traitement par batch pour √©viter les probl√®mes de m√©moire
        batch_size = 256
        predictions = []
        
        for i in range(0, len(X_tensor), batch_size):
            batch_X = X_tensor[i:i+batch_size]
            batch_pred = model(batch_X)
            predictions.append(batch_pred.cpu().numpy())
        
        # Concat√©nation de tous les batchs
        predictions = np.concatenate(predictions, axis=0).flatten()
        
        # Calcul de la MAE absolue et en pourcentage
        mae_abs = np.abs(predictions - y_test).mean()
        mae_pct = 100.0 * mae_abs / mean_flow
        
    return mae_pct, predictions

# =============================================================================
# FONCTIONS DE SAUVEGARDE POUR CLI
# =============================================================================

def sauvegarder_resultats_cli(output_dir, resultats_croises, matrice_mae, modeles_selectionnes, 
                             modeles_valides, modeles_similaires, seuil_similarite):
    """
    Sauvegarde tous les r√©sultats de l'analyse en mode CLI.
    
    Args:
        output_dir (str): Dossier de sortie
        resultats_croises (list): Liste des r√©sultats crois√©s
        matrice_mae (np.array): Matrice de performance
        modeles_selectionnes (list): Liste des mod√®les analys√©s
        modeles_valides (dict): Informations des mod√®les
        modeles_similaires (list): Paires de mod√®les similaires
        seuil_similarite (float): Seuil utilis√©
    """
    # Cr√©ation du dossier de sortie
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. Sauvegarde des r√©sultats crois√©s
    df_resultats = pd.DataFrame(resultats_croises)
    fichier_resultats = os.path.join(output_dir, f"resultats_croises_{timestamp}.csv")
    df_resultats.to_csv(fichier_resultats, index=False, encoding='utf-8')
    log_success(f"R√©sultats crois√©s sauvegard√©s: {fichier_resultats}")
    
    # 2. Sauvegarde de la matrice de performance
    n_modeles = len(modeles_selectionnes)
    df_matrice = pd.DataFrame(
        matrice_mae,
        index=[f"Capteur_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)],
        columns=[f"Donn√©es_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
    )
    fichier_matrice = os.path.join(output_dir, f"matrice_performance_{timestamp}.csv")
    df_matrice.to_csv(fichier_matrice, encoding='utf-8')
    log_success(f"Matrice de performance sauvegard√©e: {fichier_matrice}")
    
    # 3. Sauvegarde des mod√®les similaires
    if modeles_similaires:
        data_similaires = []
        for i, j, diff in modeles_similaires:
            nom_i = modeles_selectionnes[i]
            nom_j = modeles_selectionnes[j]
            data_similaires.append({
                'Capteur_1': modeles_valides[nom_i]['capteur'],
                'Intersection_1': modeles_valides[nom_i]['intersection'],
                'Capteur_2': modeles_valides[nom_j]['capteur'],
                'Intersection_2': modeles_valides[nom_j]['intersection'],
                'Difference_MAE_Moyenne': diff,
                'Seuil_Utilise': seuil_similarite
            })
        
        df_similaires = pd.DataFrame(data_similaires)
        fichier_similaires = os.path.join(output_dir, f"modeles_similaires_{timestamp}.csv")
        df_similaires.to_csv(fichier_similaires, index=False, encoding='utf-8')
        log_success(f"Mod√®les similaires sauvegard√©s: {fichier_similaires}")
    
    # 4. Sauvegarde des d√©tails des mod√®les
    resultats_details = []
    for i, nom_modele in enumerate(modeles_selectionnes):
        info = modeles_valides[nom_modele]
        resultats_details.append({
            'Modele_ID': f"Modele_{i+1}",
            'Nom_Fichier': nom_modele,
            'Capteur': info['capteur'],
            'Intersection': info['intersection'],
            'MAE_Original_Pct': info['params']['mae_original'],
            'Hidden_Size': info['params']['hidden_size'],
            'Num_Layers': info['params']['num_layers'],
            'Dropout': info['params']['dropout'],
            'Window_Size': info['params']['window_size'],
            'Learning_Rate': info['params']['learning_rate'],
            'Num_Epochs': info['params']['num_epochs']
        })
    
    df_details = pd.DataFrame(resultats_details)
    fichier_details = os.path.join(output_dir, f"details_modeles_{timestamp}.csv")
    df_details.to_csv(fichier_details, index=False, encoding='utf-8')
    log_success(f"D√©tails des mod√®les sauvegard√©s: {fichier_details}")
    
    return timestamp

def sauvegarder_visualisations_cli(output_dir, timestamp, matrice_mae, modeles_selectionnes, 
                                  modeles_valides):
    """
    Sauvegarde les visualisations en mode CLI.
    
    Args:
        output_dir (str): Dossier de sortie
        timestamp (str): Timestamp pour nommer les fichiers
        matrice_mae (np.array): Matrice de performance
        modeles_selectionnes (list): Liste des mod√®les analys√©s
        modeles_valides (dict): Informations des mod√®les
    """
    # Configuration pour √©viter les avertissements matplotlib
    plt.ioff()  # Mode non-interactif
    
    # 1. Heatmap de la matrice de performance
    try:
        n_modeles = len(modeles_selectionnes)
        df_matrice = pd.DataFrame(
            matrice_mae,
            index=[f"Capteur_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)],
            columns=[f"Donn√©es_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
        )
        
        # Remplacer les valeurs infinies pour l'affichage
        df_matrice_display = df_matrice.replace([np.inf, -np.inf], 999)
        
        plt.figure(figsize=(12, 10))
        sns.heatmap(df_matrice_display, annot=True, fmt='.1f', cmap='RdYlBu_r', 
                   cbar_kws={'label': 'MAE (%)'})
        plt.title('Matrice de Performance Crois√©e (MAE %)', fontsize=16, fontweight='bold')
        plt.xlabel('Donn√©es de test', fontsize=12)
        plt.ylabel('Mod√®les', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        fichier_heatmap = os.path.join(output_dir, f"heatmap_performance_{timestamp}.png")
        plt.savefig(fichier_heatmap, dpi=300, bbox_inches='tight')
        plt.close()
        log_success(f"Heatmap sauvegard√©e: {fichier_heatmap}")
        
    except Exception as e:
        log_error(f"Erreur lors de la sauvegarde de la heatmap: {e}")
    
    # 2. Dendrogramme de clustering
    try:
        # Calcul de la matrice de distance pour le clustering
        matrice_diff = np.zeros((n_modeles, n_modeles))
        for i in range(n_modeles):
            for j in range(n_modeles):
                if i != j:
                    mae_native = matrice_mae[j, j]
                    mae_croisee = matrice_mae[i, j]
                    diff_relative = abs(mae_croisee - mae_native)
                    matrice_diff[i, j] = diff_relative
        
        # Construction de la matrice de distance sym√©trique
        distance_matrix = np.zeros((n_modeles, n_modeles))
        for i in range(n_modeles):
            for j in range(n_modeles):
                if i != j:
                    diff_ij = matrice_diff[i, j]
                    diff_ji = matrice_diff[j, i]
                    distance_matrix[i, j] = (diff_ij + diff_ji) / 2
        
        # Clustering hi√©rarchique
        linkage_matrix = linkage(squareform(distance_matrix), method='ward')
        
        plt.figure(figsize=(12, 8))
        labels = [f"{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
        dendrogram(linkage_matrix, labels=labels, orientation='top')
        plt.title('Dendrogramme de Similarit√© des Mod√®les', fontsize=16, fontweight='bold')
        plt.ylabel('Distance', fontsize=12)
        plt.xlabel('Capteurs', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        fichier_dendro = os.path.join(output_dir, f"dendrogramme_{timestamp}.png")
        plt.savefig(fichier_dendro, dpi=300, bbox_inches='tight')
        plt.close()
        log_success(f"Dendrogramme sauvegard√©: {fichier_dendro}")
        
    except Exception as e:
        log_error(f"Erreur lors de la sauvegarde du dendrogramme: {e}")

# =============================================================================
# FONCTIONS D'INTERFACE CLI
# =============================================================================

def selectionner_modeles_interactif(modeles_valides):
    """
    Interface interactive pour s√©lectionner les mod√®les √† analyser.
    
    Args:
        modeles_valides (dict): Dictionnaire des mod√®les disponibles
        
    Returns:
        list: Liste des noms de mod√®les s√©lectionn√©s
    """
    noms_modeles = list(modeles_valides.keys())
    
    print("\n" + "="*80)
    print("S√âLECTION DES MOD√àLES √Ä ANALYSER")
    print("="*80)
    
    # Affichage de la liste des mod√®les disponibles
    print(f"\nMod√®les disponibles ({len(noms_modeles)}):")
    for i, nom in enumerate(noms_modeles):
        info = modeles_valides[nom]
        print(f"{i+1:2d}. {info['capteur']:10} ({info['intersection']:20}) - MAE: {info['params']['mae_original']}%")
    
    print("\nOptions de s√©lection:")
    print("  - Num√©ros s√©par√©s par des virgules (ex: 1,3,5)")
    print("  - Plages avec tirets (ex: 1-5)")
    print("  - 'all' pour tous les mod√®les")
    print("  - 'quit' pour annuler")
    
    while True:
        try:
            choix = input(f"\nVotre s√©lection (au moins 2 mod√®les): ").strip()
            
            if choix.lower() == 'quit':
                print("Analyse annul√©e.")
                sys.exit(0)
            
            if choix.lower() == 'all':
                return noms_modeles
            
            # Parsing de la s√©lection
            indices_selectionnes = set()
            
            # Traitement des plages et num√©ros individuels
            for partie in choix.split(','):
                partie = partie.strip()
                if '-' in partie:
                    # Plage (ex: 1-5)
                    debut, fin = map(int, partie.split('-'))
                    indices_selectionnes.update(range(debut, fin + 1))
                else:
                    # Num√©ro individuel
                    indices_selectionnes.add(int(partie))
            
            # V√©rification de la validit√© des indices
            indices_valides = [i for i in indices_selectionnes if 1 <= i <= len(noms_modeles)]
            
            if len(indices_valides) < 2:
                print("‚ö†Ô∏è  Veuillez s√©lectionner au moins 2 mod√®les.")
                continue
            
            # Conversion en noms de mod√®les
            modeles_selectionnes = [noms_modeles[i-1] for i in sorted(indices_valides)]
            
            # Confirmation de la s√©lection
            print(f"\n‚úÖ Mod√®les s√©lectionn√©s ({len(modeles_selectionnes)}):")
            for nom in modeles_selectionnes:
                info = modeles_valides[nom]
                print(f"   - {info['capteur']} ({info['intersection']})")
            
            confirmer = input("\nConfirmer cette s√©lection? (o/n): ").strip().lower()
            if confirmer in ['o', 'oui', 'y', 'yes']:
                return modeles_selectionnes
            
        except (ValueError, IndexError) as e:
            print(f"‚ùå S√©lection invalide: {e}")
            print("   Utilisez le format: 1,3,5 ou 1-5 ou 'all'")

def afficher_tableau_ascii(data, headers, title=None):
    """
    Affiche un tableau format√© en ASCII.
    
    Args:
        data (list): Donn√©es du tableau
        headers (list): En-t√™tes des colonnes
        title (str): Titre du tableau (optionnel)
    """
    if title:
        print(f"\n{title}")
        print("=" * len(title))
    
    print(tabulate(data, headers=headers, tablefmt='grid'))

def afficher_resultats_cli(resultats_croises, matrice_mae, modeles_selectionnes, 
                          modeles_valides, modeles_similaires, seuil_similarite):
    """
    Affiche tous les r√©sultats de l'analyse en mode CLI.
    
    Args:
        resultats_croises (list): Liste des r√©sultats crois√©s
        matrice_mae (np.array): Matrice de performance
        modeles_selectionnes (list): Liste des mod√®les analys√©s
        modeles_valides (dict): Informations des mod√®les
        modeles_similaires (list): Paires de mod√®les similaires
        seuil_similarite (float): Seuil utilis√©
    """
    print("\n" + "="*100)
    print("R√âSULTATS DE L'ANALYSE DE SIMILARIT√â")
    print("="*100)
    
    # 1. Tableau des performances crois√©es
    print("\nüìã R√âSUM√â DES PERFORMANCES CROIS√âES")
    print("-" * 50)
    
    # Pr√©paration des donn√©es pour le tableau
    table_data = []
    for result in resultats_croises:
        table_data.append([
            result['Mod√®le'],
            result['Test√© sur'],
            result['MAE (%)'],
            result['Diff√©rence'],
            result['Status'].replace('üè† ', '').replace('‚úÖ ', '').replace('üü¢ ', '').replace('üü° ', '').replace('üî¥ ', '')
        ])
    
    afficher_tableau_ascii(
        table_data,
        ['Mod√®le', 'Test√© sur', 'MAE (%)', 'Diff√©rence', 'Status'],
        "Performances Crois√©es D√©taill√©es"
    )
    
    # 2. Matrice de performance simplifi√©e
    print("\nüìä MATRICE DE PERFORMANCE (MAE %)")
    print("-" * 40)
    
    n_modeles = len(modeles_selectionnes)
    
    # En-t√™tes des colonnes (capteurs des donn√©es de test)
    headers = ['Mod√®le \\ Donn√©es'] + [f"Donn√©es_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
    
    # Donn√©es de la matrice
    matrix_data = []
    for i in range(n_modeles):
        row = [f"Capteur_{modeles_valides[modeles_selectionnes[i]]['capteur']}"]
        for j in range(n_modeles):
            mae_val = matrice_mae[i, j]
            if mae_val == np.inf:
                row.append("N/A")
            else:
                row.append(f"{mae_val:.1f}")
        matrix_data.append(row)
    
    afficher_tableau_ascii(matrix_data, headers)
    
    # 3. Analyse de similarit√©
    print(f"\nüîó ANALYSE DE REGROUPEMENT (Seuil: {seuil_similarite}% MAE)")
    print("-" * 55)
    
    if modeles_similaires:
        print(f"‚úÖ {len(modeles_similaires)} paire(s) de mod√®les similaires trouv√©e(s):\n")
        
        for i, (idx_i, idx_j, diff) in enumerate(modeles_similaires, 1):
            nom_i = modeles_selectionnes[idx_i]
            nom_j = modeles_selectionnes[idx_j]
            capteur_i = modeles_valides[nom_i]['capteur']
            capteur_j = modeles_valides[nom_j]['capteur'] 
            inter_i = modeles_valides[nom_i]['intersection']
            inter_j = modeles_valides[nom_j]['intersection']
            
            print(f"   {i}. {capteur_i} ({inter_i}) ‚Üî {capteur_j} ({inter_j})")
            print(f"      Diff√©rence moyenne: {diff:.2f}% MAE")
            print()
        
        # Recommandations de consolidation
        print("üí° RECOMMANDATIONS DE CONSOLIDATION:")
        print("-" * 40)
        
        # Algorithme de regroupement
        groupes = []
        modeles_assignes = set()
        
        for i, j, diff in modeles_similaires:
            if i not in modeles_assignes and j not in modeles_assignes:
                groupes.append([i, j])
                modeles_assignes.update([i, j])
            elif i in modeles_assignes:
                for groupe in groupes:
                    if i in groupe and j not in modeles_assignes:
                        groupe.append(j)
                        modeles_assignes.add(j)
                        break
            elif j in modeles_assignes:
                for groupe in groupes:
                    if j in groupe and i not in modeles_assignes:
                        groupe.append(i)
                        modeles_assignes.add(i)
                        break
        
        # Affichage des groupes
        for idx, groupe in enumerate(groupes, 1):
            print(f"\n   Groupe {idx} - Peut utiliser un mod√®le commun:")
            for model_idx in groupe:
                nom = modeles_selectionnes[model_idx]
                capteur = modeles_valides[nom]['capteur']
                intersection = modeles_valides[nom]['intersection']
                mae_orig = modeles_valides[nom]['params']['mae_original']
                print(f"     - {capteur} ({intersection}) - MAE original: {mae_orig}%")
        
        # M√©triques de r√©duction
        reduction_modeles = len(modeles_similaires)
        reduction_pct = (reduction_modeles / len(modeles_selectionnes)) * 100
        
        print(f"\nüìà IMPACT DE LA CONSOLIDATION:")
        print(f"   ‚Ä¢ R√©duction possible: {reduction_modeles} mod√®les en moins")
        print(f"   ‚Ä¢ Pourcentage de r√©duction: {reduction_pct:.1f}%")
        
    else:
        print(f"‚ùå Aucun mod√®le similaire trouv√© avec le seuil de {seuil_similarite}% MAE.")
        print("\nüí° RECOMMANDATIONS:")
        print("   ‚Ä¢ Tous les mod√®les semblent sp√©cifiques √† leur capteur")
        print("   ‚Ä¢ Consid√©rez d'assouplir le seuil de similarit√© si appropri√©")
        print("   ‚Ä¢ Analysez les caract√©ristiques des capteurs pour identifier des groupes logiques")
    
    # 4. D√©tails des mod√®les
    print(f"\nüìã D√âTAILS DES MOD√àLES ANALYS√âS")
    print("-" * 35)
    
    details_data = []
    for i, nom_modele in enumerate(modeles_selectionnes):
        info = modeles_valides[nom_modele]
        details_data.append([
            f"Mod√®le_{i+1}",
            info['capteur'],
            info['intersection'][:20] + ("..." if len(info['intersection']) > 20 else ""),
            f"{info['params']['mae_original']}%",
            info['params']['hidden_size'],
            info['params']['num_layers'],
            f"{info['params']['dropout']:.2f}",
            info['params']['window_size']
        ])
    
    afficher_tableau_ascii(
        details_data,
        ['Mod√®le', 'Capteur', 'Intersection', 'MAE Orig.', 'Hidden', 'Layers', 'Dropout', 'Window'],
        "Sp√©cifications Techniques des Mod√®les"
    )

def run_cli_analysis(args):
    """
    Lance l'analyse compl√®te en mode CLI.
    
    Args:
        args: Arguments de ligne de commande pars√©s
    """
    global CLI_MODE, VERBOSE_LEVEL
    CLI_MODE = True
    VERBOSE_LEVEL = 2 if args.verbose else (0 if args.quiet else 1)
    
    log_message("üß† ANALYSE DE SIMILARIT√â DES MOD√àLES LSTM - MODE CLI", 1)
    log_message("=" * 60, 1)
    
    # Configuration
    data_folder = args.data
    models_folder = args.models
    seuil_similarite = args.threshold
    output_dir = args.output
    
    # V√©rification des dossiers
    if not os.path.exists(data_folder):
        log_error(f"Dossier de donn√©es '{data_folder}' introuvable.")
        sys.exit(1)
    
    if not os.path.exists(models_folder):
        log_error(f"Dossier de mod√®les '{models_folder}' introuvable.")
        sys.exit(1)
    
    # D√©tection du device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    log_info(f"Device utilis√©: {device}")
    
    # D√©couverte des mod√®les
    log_message("üîç D√©couverte des mod√®les disponibles...", 1)
    modeles_disponibles = glob.glob(os.path.join(models_folder, "*.pt"))
    
    if not modeles_disponibles:
        log_error("Aucun mod√®le trouv√© dans le dossier sp√©cifi√©.")
        sys.exit(1)
    
    log_info(f"Mod√®les trouv√©s: {len(modeles_disponibles)}")
    
    # Parsing des mod√®les
    info_modeles = {}
    intersections_necessaires = set()
    capteurs_necessaires = {}
    
    for chemin in modeles_disponibles:
        nom = os.path.basename(chemin)
        params = parser_nom_modele(nom)
        
        if params:
            capteur, intersection = extraire_capteur_intersection(params['capteur_inter'])
            
            info_modeles[nom] = {
                'chemin': chemin,
                'params': params,
                'capteur': capteur,
                'intersection': intersection,
                'cle_feat': None
            }
            
            intersections_necessaires.add(intersection)
            if intersection not in capteurs_necessaires:
                capteurs_necessaires[intersection] = set()
            capteurs_necessaires[intersection].add(capteur)
    
    log_message(f"üìä Intersections identifi√©es: {list(intersections_necessaires)}", 2)
    
    # Chargement des donn√©es
    log_message("üìÅ Chargement s√©lectif des donn√©es...", 1)
    donnees = charger_donnees_selectif(data_folder, intersections_necessaires)
    
    if not donnees:
        log_error("Aucune donn√©e charg√©e.")
        sys.exit(1)
    
    # Cr√©ation des caract√©ristiques
    log_message("üîß Cr√©ation des caract√©ristiques LSTM...", 1)
    feats = creer_caracteristiques_selectif(donnees, capteurs_necessaires)
    log_success(f"Donn√©es charg√©es: {len(feats)} capteurs trouv√©s")
    
    # Matching mod√®les-donn√©es
    for nom, info in info_modeles.items():
        intersection = info['intersection']
        capteur = info['capteur']
        
        for (inter, cap), _ in feats.items():
            if intersection in inter and capteur == str(cap):
                info_modeles[nom]['cle_feat'] = (inter, cap)
                break
    
    modeles_valides = {k: v for k, v in info_modeles.items() if v['cle_feat'] is not None}
    
    if not modeles_valides:
        log_error("Aucun mod√®le ne correspond aux donn√©es disponibles.")
        sys.exit(1)
    
    log_info(f"Mod√®les valides trouv√©s: {len(modeles_valides)}")
    
    # S√©lection interactive des mod√®les
    modeles_selectionnes = selectionner_modeles_interactif(modeles_valides)
    
    if len(modeles_selectionnes) < 2:
        log_error("Au moins 2 mod√®les sont n√©cessaires pour l'analyse.")
        sys.exit(1)
    
    # Pr√©paration des donn√©es de test
    log_message("üîß Pr√©paration des donn√©es de test...", 1)
    donnees_test = {}
    
    for nom_modele in modeles_selectionnes:
        cle_feat = modeles_valides[nom_modele]['cle_feat']
        if cle_feat not in feats:
            log_error(f"Cl√© {cle_feat} introuvable dans feats")
            continue
            
        df = feats[cle_feat]
        log_message(f"üìä {nom_modele.split('_')[1]}: {len(df)} √©chantillons totaux", 2)
        
        # Division 80-20
        split_idx = int(0.8 * len(df))
        df_test = df.iloc[split_idx:]
        
        # Cr√©ation des s√©quences
        params = modeles_valides[nom_modele]['params']
        X_test, y_test = creer_sequences(df_test, params['window_size'])
        
        if len(X_test) > 0:
            donnees_test[nom_modele] = {
                'X_test': X_test,
                'y_test': y_test,
                'mean_flow': df['flow'].mean(),
                'params': params
            }
            log_message(f"‚úÖ Donn√©es test pr√©par√©es pour {nom_modele.split('_')[1]}", 2)
        else:
            log_error(f"Aucune s√©quence g√©n√©r√©e pour {nom_modele.split('_')[1]}")
    
    if len(donnees_test) < 2:
        log_error("Pas assez de donn√©es de test valides pour l'analyse")
        sys.exit(1)
    
    # Calcul de la matrice de performance
    log_message("üîç Calcul de la matrice de performance crois√©e...", 1)
    
    n_modeles = len(modeles_selectionnes)
    matrice_mae = np.zeros((n_modeles, n_modeles))
    
    total_tests = n_modeles * n_modeles
    test_count = 0
    
    for i, modele_a in enumerate(modeles_selectionnes):
        for j, modele_b in enumerate(modeles_selectionnes):
            test_count += 1
            
            if VERBOSE_LEVEL >= 2:
                print(f"Progress: {test_count}/{total_tests} - Test: {modele_a.split('_')[1]} sur donn√©es de {modele_b.split('_')[1]}")
            
            if i == j:
                matrice_mae[i, j] = modeles_valides[modele_a]['params']['mae_original']
            else:
                try:
                    if modele_b not in donnees_test:
                        matrice_mae[i, j] = np.inf
                        continue
                        
                    data_b = donnees_test[modele_b]
                    
                    model = charger_modele(
                        modeles_valides[modele_a]['chemin'],
                        modeles_valides[modele_a]['params'],
                        device
                    )
                    
                    mae_pct, predictions = evaluer_modele(
                        model, data_b['X_test'], data_b['y_test'], 
                        device, data_b['mean_flow']
                    )
                    
                    matrice_mae[i, j] = mae_pct
                    
                    del model
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                except Exception as e:
                    log_error(f"Erreur lors du test de {modele_a.split('_')[1]} sur {modele_b.split('_')[1]}: {e}")
                    matrice_mae[i, j] = np.inf
    
    log_success("Analyse de similarit√© termin√©e!")
    
    # G√©n√©ration des r√©sultats
    resultats_croises = []
    for i, modele_a in enumerate(modeles_selectionnes):
        for j, modele_b in enumerate(modeles_selectionnes):
            capteur_a = modeles_valides[modele_a]['capteur']
            capteur_b = modeles_valides[modele_b]['capteur']
            mae_value = matrice_mae[i, j]
            
            if i == j:
                status = "Natif"
                diff = 0.0
            else:
                mae_native = matrice_mae[j, j]
                diff = mae_value - mae_native
                
                if diff <= 5.0:
                    status = "Excellent" if diff <= 2.0 else "Bon"
                elif diff <= 10.0:
                    status = "Moyen"
                else:
                    status = "Faible"
            
            resultats_croises.append({
                'Mod√®le': f"Capteur {capteur_a}",
                'Test√© sur': f"Capteur {capteur_b}",
                'MAE (%)': f"{mae_value:.2f}",
                'Diff√©rence': f"{diff:+.2f}%" if i != j else "0.00%",
                'Status': status
            })
    
    # Calcul de la similarit√©
    matrice_diff = np.zeros((n_modeles, n_modeles))
    for i in range(n_modeles):
        for j in range(n_modeles):
            if i != j:
                mae_native = matrice_mae[j, j]
                mae_croisee = matrice_mae[i, j]
                diff_relative = abs(mae_croisee - mae_native)
                matrice_diff[i, j] = diff_relative
    
    modeles_similaires = []
    for i in range(n_modeles):
        for j in range(i + 1, n_modeles):
            diff_ij = matrice_diff[i, j]
            diff_ji = matrice_diff[j, i]
            diff_moyenne = (diff_ij + diff_ji) / 2
            
            if diff_moyenne <= seuil_similarite:
                modeles_similaires.append((i, j, diff_moyenne))
    
    # Affichage des r√©sultats
    afficher_resultats_cli(resultats_croises, matrice_mae, modeles_selectionnes, 
                          modeles_valides, modeles_similaires, seuil_similarite)
    
    # Sauvegarde des r√©sultats
    if output_dir:
        log_message(f"üíæ Sauvegarde des r√©sultats dans {output_dir}...", 1)
        timestamp = sauvegarder_resultats_cli(
            output_dir, resultats_croises, matrice_mae, modeles_selectionnes,
            modeles_valides, modeles_similaires, seuil_similarite
        )
        
        # Sauvegarde des visualisations
        log_message("üé® G√©n√©ration des visualisations...", 1)
        sauvegarder_visualisations_cli(
            output_dir, timestamp, matrice_mae, modeles_selectionnes, modeles_valides
        )
        
        log_success(f"Tous les r√©sultats ont √©t√© sauvegard√©s dans {output_dir}/")
    
    log_message("\nüéâ Analyse termin√©e avec succ√®s!", 1)

# =============================================================================
# FONCTION PRINCIPALE STREAMLIT (MODE GUI)
# =============================================================================

def main_streamlit():
    """
    Fonction principale de l'application Streamlit (mode GUI).
    """
    # Configuration de la page Streamlit avec titre, ic√¥ne et layout
    st.set_page_config(
        page_title="Analyse de Similarit√© des Mod√®les LSTM",
        page_icon="üß†",
        layout="wide"
    )
    
    st.title("üß† Analyse de Similarit√© des Mod√®les LSTM")
    st.markdown("---")
    
    # Sidebar pour la configuration
    st.sidebar.header("Configuration")
    
    # S√©lection des dossiers de donn√©es et mod√®les
    data_folder = st.sidebar.text_input("Dossier des donn√©es", value="./data")
    models_folder = st.sidebar.text_input("Dossier des mod√®les", value="./models")
    
    # Seuil de similarit√© pour regrouper les mod√®les
    seuil_similarite = st.sidebar.slider("Seuil de diff√©rence acceptable (MAE%)", 
                                        min_value=1.0, max_value=20.0, value=5.0, step=0.5)
    
    # D√©tection automatique du device (GPU si disponible, sinon CPU)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    st.sidebar.info(f"Device utilis√©: {device}")
    
    # V√©rification de l'existence des dossiers
    if not os.path.exists(data_folder) or not os.path.exists(models_folder):
        st.error("Veuillez v√©rifier les chemins des dossiers de donn√©es et de mod√®les.")
        return
    
    # Chargement de la liste des mod√®les disponibles
    modeles_disponibles = glob.glob(os.path.join(models_folder, "*.pt"))
    if not modeles_disponibles:
        st.error("Aucun mod√®le trouv√© dans le dossier sp√©cifi√©.")
        return
    
    st.info(f"üéØ Mod√®les trouv√©s: {len(modeles_disponibles)}")
    
    # Parsing des informations des mod√®les et identification des donn√©es n√©cessaires
    info_modeles = {}
    intersections_necessaires = set()  # Intersections √† charger
    capteurs_necessaires = {}  # Capteurs √† traiter par intersection
    
    for chemin in modeles_disponibles:
        nom = os.path.basename(chemin)
        params = parser_nom_modele(nom)
        
        if params:
            # Extraction du capteur et de l'intersection depuis le nom
            capteur, intersection = extraire_capteur_intersection(params['capteur_inter'])
            
            # Stockage des informations du mod√®le
            info_modeles[nom] = {
                'chemin': chemin,
                'params': params,
                'capteur': capteur,
                'intersection': intersection,
                'cle_feat': None  # Sera rempli lors du matching avec les donn√©es
            }
            
            # Ajout aux ensembles de donn√©es n√©cessaires
            intersections_necessaires.add(intersection)
            if intersection not in capteurs_necessaires:
                capteurs_necessaires[intersection] = set()
            capteurs_necessaires[intersection].add(capteur)
    
    # Affichage des intersections et capteurs identifi√©s
    st.write(f"**Intersections n√©cessaires**: {list(intersections_necessaires)}")
    for inter, caps in capteurs_necessaires.items():
        st.write(f"- {inter}: capteurs {list(caps)}")
    
    # Chargement optimis√©: uniquement les intersections et capteurs n√©cessaires
    with st.spinner("Chargement s√©lectif des donn√©es..."):
        donnees = charger_donnees_selectif(data_folder, intersections_necessaires)
        if not donnees:
            st.error("Aucune donn√©e charg√©e.")
            return
        
        # Cr√©ation des caract√©ristiques pour les mod√®les LSTM
        feats = creer_caracteristiques_selectif(donnees, capteurs_necessaires)
        st.success(f"Donn√©es charg√©es: {len(feats)} capteurs trouv√©s")
    
    # Association de chaque mod√®le avec ses donn√©es correspondantes
    for nom, info in info_modeles.items():
        intersection = info['intersection']
        capteur = info['capteur']
        
        # Recherche de la cl√© correspondante dans les caract√©ristiques charg√©es
        for (inter, cap), _ in feats.items():
            if intersection in inter and capteur == str(cap):
                info_modeles[nom]['cle_feat'] = (inter, cap)
                break
    
    # Filtrage des mod√®les pour lesquels les donn√©es sont disponibles
    modeles_valides = {k: v for k, v in info_modeles.items() if v['cle_feat'] is not None}
    
    if not modeles_valides:
        st.error("Aucun mod√®le ne correspond aux donn√©es disponibles.")
        return
    
    st.info(f"Mod√®les valides trouv√©s: {len(modeles_valides)}")
    
    # S√©lection des mod√®les √† analyser
    st.header("S√©lection des Mod√®les √† Analyser")
    
    noms_modeles = list(modeles_valides.keys())
    modeles_selectionnes = st.multiselect(
        "S√©lectionnez les mod√®les √† comparer:",
        options=noms_modeles,
        default=noms_modeles[:min(5, len(noms_modeles))],  # Max 5 par d√©faut
        help="S√©lectionnez au moins 2 mod√®les pour l'analyse de similarit√©"
    )
    
    if len(modeles_selectionnes) < 2:
        st.warning("Veuillez s√©lectionner au moins 2 mod√®les pour l'analyse.")
        return
    
    # Analyse de similarit√© principale
    if st.button("üîç Lancer l'Analyse de Similarit√©"):
        
        # Pr√©paration des donn√©es de test
        donnees_test = {}
        st.write("üîß Pr√©paration des donn√©es de test...")
        
        # Pour chaque mod√®le s√©lectionn√©, pr√©parer ses donn√©es de test
        for nom_modele in modeles_selectionnes:
            cle_feat = modeles_valides[nom_modele]['cle_feat']
            if cle_feat not in feats:
                st.error(f"Cl√© {cle_feat} introuvable dans feats")
                continue
                
            df = feats[cle_feat]
            st.write(f"üìä {nom_modele.split('_')[1]}: {len(df)} √©chantillons totaux")
            
            # Division 80-20 pour train/test (on utilise seulement le test)
            split_idx = int(0.8 * len(df))
            df_test = df.iloc[split_idx:]
            st.write(f"Test: {len(df_test)} √©chantillons")
            
            # Cr√©ation des s√©quences pour ce mod√®le
            params = modeles_valides[nom_modele]['params']
            X_test, y_test = creer_sequences(df_test, params['window_size'])
            
            st.write(f"S√©quences: {X_test.shape if len(X_test) > 0 else 'Aucune'}")
            
            # Stockage des donn√©es de test si des s√©quences ont √©t√© cr√©√©es
            if len(X_test) > 0:
                donnees_test[nom_modele] = {
                    'X_test': X_test,
                    'y_test': y_test,
                    'mean_flow': df['flow'].mean(),  # Pour normaliser la MAE
                    'params': params
                }
                st.success(f"‚úÖ Donn√©es test pr√©par√©es pour {nom_modele.split('_')[1]}")
            else:
                st.error(f"‚ùå Aucune s√©quence g√©n√©r√©e pour {nom_modele.split('_')[1]}")
        
        st.write(f"Total mod√®les avec donn√©es de test: {len(donnees_test)}")
        
        if len(donnees_test) < 2:
            st.error("Pas assez de donn√©es de test valides pour l'analyse")
            return
        
        # Calcul de la matrice de performance crois√©e
        st.header("üìä Matrice de Similarit√©")
        
        n_modeles = len(modeles_selectionnes)
        matrice_mae = np.zeros((n_modeles, n_modeles))
        
        # Barres de progression pour l'utilisateur
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Calcul de toutes les combinaisons mod√®le_A test√© sur donn√©es_B
        for i, modele_a in enumerate(modeles_selectionnes):
            for j, modele_b in enumerate(modeles_selectionnes):
                
                # Mise √† jour de la progression
                progress = (i * n_modeles + j + 1) / (n_modeles * n_modeles)
                progress_bar.progress(progress)
                status_text.text(f"Test: {modele_a.split('_')[1]} sur donn√©es de {modele_b.split('_')[1]}")
                
                if i == j:
                    # Performance native du mod√®le (diagonale de la matrice)
                    matrice_mae[i, j] = modeles_valides[modele_a]['params']['mae_original']
                else:
                    # Test crois√©: mod√®le A test√© sur donn√©es B
                    try:
                        # V√©rification de la disponibilit√© des donn√©es de test
                        if modele_b not in donnees_test:
                            matrice_mae[i, j] = np.inf
                            continue
                            
                        data_b = donnees_test[modele_b]
                        
                        # Chargement du mod√®le A
                        model = charger_modele(
                            modeles_valides[modele_a]['chemin'],
                            modeles_valides[modele_a]['params'],
                            device
                        )
                        
                        # √âvaluation du mod√®le A sur les donn√©es B
                        mae_pct, predictions = evaluer_modele(
                            model, data_b['X_test'], data_b['y_test'], 
                            device, data_b['mean_flow']
                        )
                        
                        matrice_mae[i, j] = mae_pct
                        
                        # Nettoyage m√©moire pour √©viter l'accumulation
                        del model
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors du test de {modele_a.split('_')[1]} sur {modele_b.split('_')[1]}: {e}")
                        matrice_mae[i, j] = np.inf
        
        # Nettoyage de l'interface
        progress_bar.empty()
        status_text.empty()
        
        # Affichage des r√©sultats de performance
        st.success("üéØ Analyse de similarit√© termin√©e !")
        
        # Tableau r√©capitulatif des performances crois√©es
        st.subheader("üìã R√©sum√© des Performances Crois√©es")
        
        resultats_croises = []
        for i, modele_a in enumerate(modeles_selectionnes):
            for j, modele_b in enumerate(modeles_selectionnes):
                capteur_a = modeles_valides[modele_a]['capteur']
                capteur_b = modeles_valides[modele_b]['capteur']
                mae_value = matrice_mae[i, j]
                
                if i == j:
                    # Performance native
                    status = "üè† Natif"
                    diff = 0.0
                else:
                    # Performance crois√©e vs native
                    mae_native = matrice_mae[j, j]  # Performance native du mod√®le B
                    diff = mae_value - mae_native
                    
                    # Classification de la performance selon la diff√©rence avec le mod√®le natif
                    if diff <= 5.0:
                        status = "‚úÖ Excellent" if diff <= 2.0 else "üü¢ Bon"
                    elif diff <= 10.0:
                        status = "üü° Moyen"
                    else:
                        status = "üî¥ Faible"
                
                # Ajout des r√©sultats au tableau r√©capitulatif
                resultats_croises.append({
                    'Mod√®le': f"Capteur {capteur_a}",
                    'Test√© sur': f"Capteur {capteur_b}",
                    'MAE (%)': f"{mae_value:.2f}",
                    'Diff√©rence': f"{diff:+.2f}%" if i != j else "0.00%",
                    'Status': status
                })
        
        # Affichage du tableau sous forme de DataFrame interactif
        df_resultats = pd.DataFrame(resultats_croises)
        st.dataframe(df_resultats, use_container_width=True, hide_index=True)
        
        # Visualisation de la matrice de performance
        # Cr√©ation d'une heatmap interactive avec Plotly
        df_matrice = pd.DataFrame(
            matrice_mae,
            index=[f"Capteur_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)],
            columns=[f"Donn√©es_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
        )
        
        # Remplacement des valeurs infinies pour l'affichage
        df_matrice_display = df_matrice.replace([np.inf, -np.inf], 999)
        
        # Cr√©ation de la heatmap avec √©chelle de couleurs appropri√©e
        fig_heatmap = px.imshow(
            df_matrice_display,
            labels=dict(x="Donn√©es de test", y="Mod√®les", color="MAE %"),
            title="Matrice de Performance Crois√©e (MAE %)",
            color_continuous_scale="RdYlBu_r",  # Rouge = mauvais, Bleu = bon
            text_auto=".1f"  # Affichage des valeurs avec 1 d√©cimale
        )
        fig_heatmap.update_layout(height=500)
        
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # Analyse de similarit√© et clustering
        st.header("üîó Analyse de Regroupement")
        
        # Calcul des diff√©rences relatives entre performances crois√©es et natives
        matrice_diff = np.zeros((n_modeles, n_modeles))
        for i in range(n_modeles):
            for j in range(n_modeles):
                if i != j:
                    mae_native = matrice_mae[j, j]  # Performance native du mod√®le j
                    mae_croisee = matrice_mae[i, j]  # Performance du mod√®le i sur donn√©es j
                    diff_relative = abs(mae_croisee - mae_native)
                    matrice_diff[i, j] = diff_relative
        
        # Identification des paires de mod√®les similaires
        modeles_similaires = []
        for i in range(n_modeles):
            for j in range(i + 1, n_modeles):
                # Diff√©rence bidirectionnelle (i sur j ET j sur i)
                diff_ij = matrice_diff[i, j]  # Mod√®le i test√© sur donn√©es j
                diff_ji = matrice_diff[j, i]  # Mod√®le j test√© sur donn√©es i
                diff_moyenne = (diff_ij + diff_ji) / 2
                
                # Test du seuil de similarit√©
                if diff_moyenne <= seuil_similarite:
                    modeles_similaires.append((i, j, diff_moyenne))
        
        # Affichage des mod√®les similaires
        if modeles_similaires:
            st.success(f"üéØ Mod√®les similaires trouv√©s (seuil: {seuil_similarite}% MAE):")
            
            cols = st.columns(2)
            
            # Colonne 1: Liste des paires similaires
            with cols[0]:
                for i, j, diff in modeles_similaires:
                    nom_i = modeles_selectionnes[i]
                    nom_j = modeles_selectionnes[j]
                    
                    st.info(f"**{modeles_valides[nom_i]['capteur']} ({modeles_valides[nom_i]['intersection']})** ‚Üî "
                           f"**{modeles_valides[nom_j]['capteur']} ({modeles_valides[nom_j]['intersection']})**\n\n"
                           f"Diff√©rence moyenne: {diff:.2f}% MAE")
            
            # Colonne 2: Dendrogramme de clustering hi√©rarchique
            with cols[1]:
                st.subheader("Dendrogramme de Regroupement")
                
                # Construction de la matrice de distance sym√©trique
                distance_matrix = np.zeros((n_modeles, n_modeles))
                for i in range(n_modeles):
                    for j in range(n_modeles):
                        if i != j:
                            diff_ij = matrice_diff[i, j]
                            diff_ji = matrice_diff[j, i]
                            distance_matrix[i, j] = (diff_ij + diff_ji) / 2
                
                # Clustering hi√©rarchique avec m√©thode de Ward
                linkage_matrix = linkage(squareform(distance_matrix), method='ward')
                
                # Cr√©ation du dendrogramme
                fig, ax = plt.subplots(figsize=(10, 6))
                labels = [f"{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
                dendrogram(linkage_matrix, labels=labels, ax=ax, orientation='top')
                ax.set_title("Dendrogramme de Similarit√© des Mod√®les")
                ax.set_ylabel("Distance")
                plt.xticks(rotation=45)
                st.pyplot(fig)
        
        else:
            st.warning(f"Aucun mod√®le similaire trouv√© avec le seuil de {seuil_similarite}% MAE.")
        
        # G√©n√©ration des recommandations
        st.header("üí° Recommandations")
        
        if modeles_similaires:
            st.markdown("### Strat√©gies de Consolidation Possibles:")
            
            # Algorithme de regroupement des mod√®les similaires
            groupes = []
            modeles_assignes = set()
            
            # Premi√®re passe: cr√©er des groupes initiaux
            for i, j, diff in modeles_similaires:
                if i not in modeles_assignes and j not in modeles_assignes:
                    groupes.append([i, j])
                    modeles_assignes.update([i, j])
                elif i in modeles_assignes:
                    # Ajouter j au groupe contenant i
                    for groupe in groupes:
                        if i in groupe and j not in modeles_assignes:
                            groupe.append(j)
                            modeles_assignes.add(j)
                            break
                elif j in modeles_assignes:
                    # Ajouter i au groupe contenant j
                    for groupe in groupes:
                        if j in groupe and i not in modeles_assignes:
                            groupe.append(i)
                            modeles_assignes.add(i)
                            break
            
            # Affichage des groupes identifi√©s
            for idx, groupe in enumerate(groupes, 1):
                st.success(f"**Groupe {idx}**: Peut utiliser un mod√®le commun")
                for model_idx in groupe:
                    nom = modeles_selectionnes[model_idx]
                    capteur = modeles_valides[nom]['capteur']
                    intersection = modeles_valides[nom]['intersection']
                    mae_orig = modeles_valides[nom]['params']['mae_original']
                    st.write(f"- {capteur} ({intersection}) - MAE original: {mae_orig}%")
            
            # Calcul des m√©triques de r√©duction
            reduction_modeles = len(modeles_similaires)
            reduction_pct = (reduction_modeles / len(modeles_selectionnes)) * 100
            
            st.info(f"**R√©duction potentielle**: {reduction_modeles} mod√®les en moins "
                   f"({reduction_pct:.1f}% de r√©duction)")
        
        else:
            st.markdown("### Recommandations:")
            st.write("- Tous les mod√®les semblent sp√©cifiques √† leur capteur")
            st.write("- Consid√©rez d'assouplir le seuil de similarit√© si appropri√©")
            st.write("- Analysez les caract√©ristiques des capteurs pour identifier des groupes logiques")
        
        # Tableau d√©taill√© des r√©sultats
        st.header("üìã R√©sultats D√©taill√©s")
        
        # Compilation des informations d√©taill√©es de chaque mod√®le
        resultats_details = []
        for i, nom_modele in enumerate(modeles_selectionnes):
            info = modeles_valides[nom_modele]
            resultats_details.append({
                'Mod√®le': f"Mod√®le_{i+1}",
                'Capteur': info['capteur'],
                'Intersection': info['intersection'],
                'MAE Original (%)': info['params']['mae_original'],
                'Hidden Size': info['params']['hidden_size'],
                'Layers': info['params']['num_layers'],
                'Dropout': info['params']['dropout'],
                'Window Size': info['params']['window_size']
            })
        
        # Affichage du tableau r√©capitulatif
        df_details = pd.DataFrame(resultats_details)
        st.dataframe(df_details, use_container_width=True)

# =============================================================================
# FONCTION PRINCIPALE ET PARSING DES ARGUMENTS
# =============================================================================

def main():
    """
    Point d'entr√©e principal de l'application.
    G√®re le choix entre mode CLI et mode GUI.
    """
    parser = argparse.ArgumentParser(
        description="Analyse de similarit√© des mod√®les LSTM pour capteurs de trafic",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:

  Mode GUI (Streamlit):
    python analyse_similarite_lstm.py

  Mode CLI:
    python analyse_similarite_lstm.py --cli --data ./data --models ./models
    
  Mode CLI avec options:
    python analyse_similarite_lstm.py --cli --data ./data --models ./models \\
                                      --threshold 3.0 --output ./resultats --verbose

  Mode CLI silencieux:
    python analyse_similarite_lstm.py --cli --data ./data --models ./models --quiet
        """
    )
    
    # Arguments principaux
    parser.add_argument(
        '--cli', 
        action='store_true',
        help='Lance l\'application en mode ligne de commande (CLI) au lieu du mode GUI Streamlit'
    )
    
    # Arguments pour le mode CLI
    cli_group = parser.add_argument_group('Options CLI')
    
    cli_group.add_argument(
        '--data', 
        type=str, 
        default='./data',
        help='Dossier contenant les donn√©es CSV des capteurs (d√©faut: ./data)'
    )
    
    cli_group.add_argument(
        '--models', 
        type=str, 
        default='./models',
        help='Dossier contenant les mod√®les LSTM (.pt) (d√©faut: ./models)'
    )
    
    cli_group.add_argument(
        '--threshold', 
        type=float, 
        default=5.0,
        help='Seuil de diff√©rence MAE acceptable pour consid√©rer deux mod√®les comme similaires (d√©faut: 5.0%%)'
    )
    
    cli_group.add_argument(
        '--output', 
        type=str, 
        default='./resultats',
        help='Dossier de sortie pour les r√©sultats CSV et PNG (d√©faut: ./resultats)'
    )
    
    # Options de verbosit√©
    verbosity_group = parser.add_mutually_exclusive_group()
    verbosity_group.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Mode verbeux: affiche plus d\'informations de d√©bogage'
    )
    
    verbosity_group.add_argument(
        '--quiet', '-q',
        action='store_true', 
        help='Mode silencieux: affiche seulement les erreurs'
    )
    
    # Parsing des arguments
    args = parser.parse_args()
    
    # V√©rification des d√©pendances selon le mode choisi
    if args.cli:
        # Mode CLI: v√©rifier tabulate
        try:
            import tabulate
        except ImportError:
            print("ERREUR: Le module 'tabulate' est requis pour le mode CLI.", file=sys.stderr)
            print("Installez-le avec: pip install tabulate", file=sys.stderr)
            sys.exit(1)
        
        # Lancement de l'analyse CLI
        run_cli_analysis(args)
        
    else:
        # Mode GUI: v√©rifier Streamlit
        if not STREAMLIT_AVAILABLE:
            print("ERREUR: Streamlit n'est pas install√©.", file=sys.stderr)
            print("Installez-le avec: pip install streamlit", file=sys.stderr)
            print("Ou utilisez le mode CLI avec --cli", file=sys.stderr)
            sys.exit(1)
        
        # Lancement de l'interface Streamlit
        main_streamlit()

# =============================================================================
# POINT D'ENTR√âE DE L'APPLICATION
# =============================================================================

if __name__ == "__main__":
    main()
