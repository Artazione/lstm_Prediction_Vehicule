"""
Script: analyse_similarite_lstm.py
Auteur: Jules Lef√®vre <jules.lefevre@etudiant.univ-reims.fr>
Date de cr√©ation: 21/07/2025
Description: Application Streamlit pour analyser la similarit√© entre mod√®les LSTM 
            entra√Æn√©s sur diff√©rents capteurs de trafic. L'outil permet d'identifier 
            les mod√®les qui peuvent √™tre consolid√©s en un seul mod√®le g√©n√©raliste,
            bas√© sur l'analyse des performances crois√©es (test d'un mod√®le sur les 
            donn√©es d'un autre capteur). Inclut visualisations interactives, 
            clustering hi√©rarchique et recommandations de consolidation.
"""

import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import os
import re
import glob
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import squareform
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION DE L'APPLICATION STREAMLIT
# =============================================================================

# Configuration de la page Streamlit avec titre, ic√¥ne et layout
st.set_page_config(
    page_title="Analyse de Similarit√© des Mod√®les LSTM",
    page_icon="üß†",
    layout="wide"
)

# =============================================================================
# D√âFINITION DE L'ARCHITECTURE LSTM
# =============================================================================

class RegresseurLSTM(nn.Module):
    """
    Classe d√©finissant l'architecture du mod√®le LSTM pour la r√©gression.
    
    Architecture:
    - Couches LSTM empil√©es avec dropout
    - Couche lin√©aire finale pour la pr√©diction
    
    Args:
        in_size (int): Nombre de features d'entr√©e (6 dans notre cas)
        hid_size (int): Taille des couches cach√©es LSTM
        n_layers (int): Nombre de couches LSTM empil√©es
        dropout (float): Taux de dropout entre les couches LSTM
    """
    def __init__(self, in_size, hid_size, n_layers, dropout):
        super().__init__()
        # Couches LSTM empil√©es avec dropout et batch_first=True pour faciliter le traitement
        self.lstm = nn.LSTM(in_size, hid_size, n_layers,
                            dropout=dropout, batch_first=True)
        # Couche lin√©aire finale pour pr√©dire une seule valeur (flux de v√©hicules)
        self.fc = nn.Linear(hid_size, 1)

    def forward(self, x):
        """
        Propagation avant du mod√®le.
        
        Args:
            x (torch.Tensor): S√©quences d'entr√©e de forme (batch_size, seq_len, features)
            
        Returns:
            torch.Tensor: Pr√©dictions de forme (batch_size, 1)
        """
        # Passage dans les couches LSTM, on r√©cup√®re seulement les outputs
        out, _ = self.lstm(x)
        # On utilise seulement le dernier timestep pour la pr√©diction
        return self.fc(out[:, -1, :])

# =============================================================================
# FONCTIONS DE CHARGEMENT ET PR√âPARATION DES DONN√âES
# =============================================================================

@st.cache_data
def charger_donnees_selectif(dossier_racine, intersections_necessaires):
    """
    Charge s√©lectivement les donn√©es CSV des intersections n√©cessaires pour optimiser les performances.
    
    Cette fonction lit uniquement les donn√©es des intersections qui ont des mod√®les associ√©s,
    √©vitant ainsi de charger inutilement toutes les donn√©es disponibles.
    
    Args:
        dossier_racine (str): Chemin vers le dossier contenant les sous-dossiers d'intersections
        intersections_necessaires (set): Ensemble des noms d'intersections √† charger
        
    Returns:
        dict: Dictionnaire {nom_intersection: DataFrame_pivot} avec les donn√©es temporelles
              index√©es par datetime et colonnes = capteurs
    """
    donnees = {}
    
    # V√©rification de l'existence du dossier racine
    if not os.path.exists(dossier_racine):
        st.error(f"Dossier '{dossier_racine}' introuvable.")
        return donnees
    
    st.info(f"üéØ Chargement s√©lectif pour: {list(intersections_necessaires)}")
    
    # Parcours de tous les dossiers d'intersections
    for inter in sorted(os.listdir(dossier_racine)):
        # V√©rifier si cette intersection est n√©cessaire (optimisation performance)
        if not any(intersection in inter for intersection in intersections_necessaires):
            continue
            
        chemin = os.path.join(dossier_racine, inter)
        if not os.path.isdir(chemin):
            continue
            
        # Recherche du fichier CSV dans le dossier
        csvs = [f for f in os.listdir(chemin) if f.lower().endswith('.csv')]
        if not csvs:
            continue
            
        try:
            # Chargement optimis√©: seulement les colonnes n√©cessaires
            df = pd.read_csv(
                os.path.join(chemin, csvs[0]), sep=';', encoding='utf-8',
                usecols=['count_point_name', 'measure_datetime', 'flow[veh/h]']
            )
            
            # Conversion des dates avec gestion des erreurs
            df['measure_datetime'] = pd.to_datetime(
                df['measure_datetime'], utc=True, errors='coerce'
            )
            
            # Suppression des lignes avec des valeurs manquantes critiques
            df = df.dropna(subset=['measure_datetime', 'flow[veh/h]'])
            
            # Conversion du timezone UTC vers Europe/Paris
            df['measure_datetime'] = df['measure_datetime'].dt.tz_convert('Europe/Paris')
            
            # Cr√©ation du tableau pivot: lignes=datetime, colonnes=capteurs, valeurs=flux
            pivot = df.pivot(
                index='measure_datetime', columns='count_point_name', values='flow[veh/h]'
            ).sort_index()
            
            donnees[inter] = pivot
            st.success(f"‚úÖ {inter}: {pivot.shape[0]} lignes, {pivot.shape[1]} capteurs")
            
        except Exception as e:
            st.error(f"‚ùå Erreur {inter}: {e}")
    
    return donnees

@st.cache_data
def creer_caracteristiques_selectif(donnees, capteurs_necessaires):
    """
    Cr√©e les caract√©ristiques d'entr√©e pour les mod√®les LSTM, uniquement pour les capteurs n√©cessaires.
    
    Pour chaque capteur, g√©n√®re:
    - flow: flux du capteur (variable cible)
    - mean_flow_others: flux moyen des autres capteurs de la m√™me intersection
    - hour_cos: encodage cyclique de l'heure (cosinus)
    - ma3, ma6, ma12: moyennes mobiles sur 3, 6 et 12 p√©riodes
    
    Args:
        donnees (dict): Donn√©es pivot par intersection
        capteurs_necessaires (dict): {intersection: set_of_capteurs} √† traiter
        
    Returns:
        dict: {(intersection, capteur): DataFrame_avec_features}
    """
    feats = {}
    
    for inter, pivot in donnees.items():
        # Identifier quels capteurs sont n√©cessaires pour cette intersection
        capteurs_inter = set()
        for intersection, capteurs in capteurs_necessaires.items():
            if intersection in inter:
                capteurs_inter.update(capteurs)
        
        if not capteurs_inter:
            continue
            
        # Remplissage des valeurs manquantes par la moyenne de chaque capteur
        filled = pivot.fillna(pivot.mean())
        
        # Calcul du flux total de l'intersection et du nombre de capteurs
        total = filled.sum(axis=1).values.reshape(-1, 1)
        count = filled.shape[1]
        
        # Calcul du flux moyen des "autres" capteurs pour chaque capteur
        # (total - capteur_actuel) / (nombre_capteurs - 1)
        others = (total - filled.values) / (count - 1)
        df_others = pd.DataFrame(others, index=filled.index, columns=filled.columns)
        
        # Traitement de chaque capteur individuellement
        for cap in pivot.columns:
            # V√©rifier si ce capteur est n√©cessaire (optimisation)
            if str(cap) not in capteurs_inter:
                continue
                
            # Cr√©ation du DataFrame de caract√©ristiques pour ce capteur
            dfc = pd.DataFrame(index=pivot.index)
            
            # Feature 1: flux du capteur (variable cible)
            dfc['flow'] = pivot[cap]
            
            # Feature 2: flux moyen des autres capteurs (contexte spatial)
            dfc['mean_flow_others'] = df_others[cap]
            
            # Feature 3: encodage cyclique de l'heure (contexte temporel)
            heures = dfc.index.hour
            dfc['hour_cos'] = np.cos(2 * np.pi * heures / 24)
            
            # Features 4-6: moyennes mobiles pour capturer les tendances
            for w in (3, 6, 12):
                dfc[f'ma{w}'] = dfc['flow'].rolling(window=w, min_periods=1).mean()
            
            # Suppression des lignes avec des valeurs manquantes dans 'flow'
            feats[(inter, cap)] = dfc.dropna(subset=['flow'])
            st.info(f"üìä Caract√©ristiques cr√©√©es pour {inter} - capteur {cap}")
    
    return feats

# =============================================================================
# FONCTIONS DE PR√âPARATION DES S√âQUENCES ET PARSING
# =============================================================================

def creer_sequences(df, seq_len):
    """
    Transforme un DataFrame de caract√©ristiques en s√©quences pour l'entra√Ænement LSTM.
    
    Cr√©e des s√©quences glissantes de longueur seq_len, o√π chaque s√©quence X pr√©dit
    la valeur y au timestep suivant.
    
    Args:
        df (DataFrame): DataFrame avec les colonnes de caract√©ristiques
        seq_len (int): Longueur des s√©quences d'entr√©e
        
    Returns:
        tuple: (X, y) o√π X.shape = (n_sequences, seq_len, n_features)
               et y.shape = (n_sequences,)
    """
    # Colonnes de caract√©ristiques dans l'ordre attendu par le mod√®le
    cols = ['flow', 'hour_cos', 'mean_flow_others', 'ma3', 'ma6', 'ma12']
    arr = df[cols].values
    
    X, y = [], []
    # Cr√©ation des s√©quences glissantes
    for i in range(seq_len, len(arr)):
        # S√©quence d'entr√©e: timesteps [i-seq_len:i]
        X.append(arr[i-seq_len:i])
        # Valeur cible: flux au timestep i
        y.append(arr[i, 0])  # 0 = index de 'flow'
        
    return np.array(X), np.array(y)

def parser_nom_modele(nom_fichier):
    """
    Parse le nom d'un fichier de mod√®le pour extraire ses hyperparam√®tres.
    
    Format attendu: sensor_CAPTEUR_INTERSECTION_bs_hs_nl_do_lr_ep_ws_mae.pt
    Exemple: sensor_A12_Intersection1_bs32_hs64_nl2_do20_lr1e-3_ep100_ws24_mae150.pt
    
    Args:
        nom_fichier (str): Nom du fichier de mod√®le
        
    Returns:
        dict or None: Dictionnaire des param√®tres extraits ou None si parsing √©choue
    """
    # Expression r√©guli√®re pour extraire tous les param√®tres du nom de fichier
    pattern = r'sensor_(.+)_bs(\d+)_hs(\d+)_nl(\d+)_do(\d+)_lr(\d+e-\d+)_ep(\d+)_ws(\d+)_mae(\d+)\.pt'
    match = re.match(pattern, nom_fichier)
    
    if match:
        return {
            'capteur_inter': match.group(1),      # Identifiant capteur_intersection
            'batch_size': int(match.group(2)),    # Taille des batchs
            'hidden_size': int(match.group(3)),   # Taille des couches cach√©es
            'num_layers': int(match.group(4)),    # Nombre de couches LSTM
            'dropout': int(match.group(5)) / 100.0,  # Taux de dropout (converti en decimal)
            'learning_rate': float(match.group(6)),  # Taux d'apprentissage
            'num_epochs': int(match.group(7)),    # Nombre d'√©poques d'entra√Ænement
            'window_size': int(match.group(8)),   # Taille des s√©quences
            'mae_original': int(match.group(9))   # MAE original du mod√®le (en centi√®mes de %)
        }
    return None

def extraire_capteur_intersection(capteur_inter):
    """
    S√©pare l'identifiant capteur_intersection en capteur et intersection.
    
    Args:
        capteur_inter (str): Cha√Æne au format "capteur_intersection"
        
    Returns:
        tuple: (capteur, intersection)
    """
    parts = capteur_inter.split('_')
    if len(parts) >= 2:
        capteur = parts[0]  # Premier √©l√©ment = nom du capteur
        intersection = '_'.join(parts[1:])  # Reste = nom de l'intersection
        return capteur, intersection
    return capteur_inter, ""

# =============================================================================
# FONCTIONS DE CHARGEMENT ET √âVALUATION DES MOD√àLES
# =============================================================================

@st.cache_resource
def charger_modele(chemin_modele, params, device):
    """
    Charge un mod√®le LSTM depuis un fichier .pt.
    
    Utilise le d√©corateur @st.cache_resource pour √©viter de recharger
    le m√™me mod√®le plusieurs fois pendant la session.
    
    Args:
        chemin_modele (str): Chemin vers le fichier .pt
        params (dict): Param√®tres du mod√®le pour reconstruire l'architecture
        device (torch.device): Device sur lequel charger le mod√®le
        
    Returns:
        RegresseurLSTM: Mod√®le charg√© et pr√™t pour l'√©valuation
    """
    # Reconstruction de l'architecture avec les param√®tres extraits
    model = RegresseurLSTM(6, params['hidden_size'], params['num_layers'], params['dropout'])
    
    # Chargement des poids sauvegard√©s
    model.load_state_dict(torch.load(chemin_modele, map_location=device))
    
    # D√©placement vers le device appropri√© et passage en mode √©valuation
    model.to(device)
    model.eval()
    
    return model

def evaluer_modele(model, X_test, y_test, device, mean_flow):
    """
    √âvalue un mod√®le sur un jeu de donn√©es de test.
    
    Calcule la MAE en pourcentage par rapport au flux moyen pour une interpr√©tation
    plus intuitive des performances.
    
    Args:
        model (RegresseurLSTM): Mod√®le √† √©valuer
        X_test (np.array): S√©quences de test
        y_test (np.array): Valeurs cibles de test
        device (torch.device): Device pour les calculs
        mean_flow (float): Flux moyen pour normaliser la MAE
        
    Returns:
        tuple: (mae_percentage, predictions)
    """
    model.eval()
    with torch.no_grad():
        # Conversion en tenseurs PyTorch
        X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
        y_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)
        
        # Traitement par batch pour √©viter les probl√®mes de m√©moire
        batch_size = 256
        predictions = []
        
        for i in range(0, len(X_tensor), batch_size):
            batch_X = X_tensor[i:i+batch_size]
            batch_pred = model(batch_X)
            predictions.append(batch_pred.cpu().numpy())
        
        # Concat√©nation de tous les batchs
        predictions = np.concatenate(predictions, axis=0).flatten()
        
        # Calcul de la MAE absolue et en pourcentage
        mae_abs = np.abs(predictions - y_test).mean()
        mae_pct = 100.0 * mae_abs / mean_flow
        
    return mae_pct, predictions

# =============================================================================
# FONCTION PRINCIPALE DE L'APPLICATION
# =============================================================================

def main():
    """
    Fonction principale de l'application Streamlit.
    
    Orchestration compl√®te de l'analyse de similarit√©:
    1. Configuration de l'interface utilisateur
    2. Chargement s√©lectif des donn√©es et mod√®les
    3. Calcul de la matrice de performance crois√©e
    4. Analyse de similarit√© et clustering
    5. G√©n√©ration des recommandations
    """
    
    # =============================================================================
    # INTERFACE UTILISATEUR ET CONFIGURATION
    # =============================================================================
    
    st.title("üß† Analyse de Similarit√© des Mod√®les LSTM")
    st.markdown("---")
    
    # Sidebar pour la configuration
    st.sidebar.header("Configuration")
    
    # S√©lection des dossiers de donn√©es et mod√®les
    data_folder = st.sidebar.text_input("Dossier des donn√©es", value="./data")
    models_folder = st.sidebar.text_input("Dossier des mod√®les", value="./models")
    
    # Seuil de similarit√© pour regrouper les mod√®les
    seuil_similarite = st.sidebar.slider("Seuil de diff√©rence acceptable (MAE%)", 
                                        min_value=1.0, max_value=20.0, value=5.0, step=0.5)
    
    # D√©tection automatique du device (GPU si disponible, sinon CPU)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    st.sidebar.info(f"Device utilis√©: {device}")
    
    # V√©rification de l'existence des dossiers
    if not os.path.exists(data_folder) or not os.path.exists(models_folder):
        st.error("Veuillez v√©rifier les chemins des dossiers de donn√©es et de mod√®les.")
        return
    
    # =============================================================================
    # D√âCOUVERTE ET PARSING DES MOD√àLES DISPONIBLES
    # =============================================================================
    
    # Chargement de la liste des mod√®les disponibles
    modeles_disponibles = glob.glob(os.path.join(models_folder, "*.pt"))
    if not modeles_disponibles:
        st.error("Aucun mod√®le trouv√© dans le dossier sp√©cifi√©.")
        return
    
    st.info(f"üéØ Mod√®les trouv√©s: {len(modeles_disponibles)}")
    
    # Parsing des informations des mod√®les et identification des donn√©es n√©cessaires
    info_modeles = {}
    intersections_necessaires = set()  # Intersections √† charger
    capteurs_necessaires = {}  # Capteurs √† traiter par intersection
    
    for chemin in modeles_disponibles:
        nom = os.path.basename(chemin)
        params = parser_nom_modele(nom)
        
        if params:
            # Extraction du capteur et de l'intersection depuis le nom
            capteur, intersection = extraire_capteur_intersection(params['capteur_inter'])
            
            # Stockage des informations du mod√®le
            info_modeles[nom] = {
                'chemin': chemin,
                'params': params,
                'capteur': capteur,
                'intersection': intersection,
                'cle_feat': None  # Sera rempli lors du matching avec les donn√©es
            }
            
            # Ajout aux ensembles de donn√©es n√©cessaires
            intersections_necessaires.add(intersection)
            if intersection not in capteurs_necessaires:
                capteurs_necessaires[intersection] = set()
            capteurs_necessaires[intersection].add(capteur)
    
    # Affichage des intersections et capteurs identifi√©s
    st.write(f"**Intersections n√©cessaires**: {list(intersections_necessaires)}")
    for inter, caps in capteurs_necessaires.items():
        st.write(f"- {inter}: capteurs {list(caps)}")
    
    # =============================================================================
    # CHARGEMENT S√âLECTIF DES DONN√âES
    # =============================================================================
    
    # Chargement optimis√©: uniquement les intersections et capteurs n√©cessaires
    with st.spinner("Chargement s√©lectif des donn√©es..."):
        donnees = charger_donnees_selectif(data_folder, intersections_necessaires)
        if not donnees:
            st.error("Aucune donn√©e charg√©e.")
            return
        
        # Cr√©ation des caract√©ristiques pour les mod√®les LSTM
        feats = creer_caracteristiques_selectif(donnees, capteurs_necessaires)
        st.success(f"Donn√©es charg√©es: {len(feats)} capteurs trouv√©s")
    
    # =============================================================================
    # MATCHING MOD√àLES-DONN√âES
    # =============================================================================
    
    # Association de chaque mod√®le avec ses donn√©es correspondantes
    for nom, info in info_modeles.items():
        intersection = info['intersection']
        capteur = info['capteur']
        
        # Recherche de la cl√© correspondante dans les caract√©ristiques charg√©es
        for (inter, cap), _ in feats.items():
            if intersection in inter and capteur == str(cap):
                info_modeles[nom]['cle_feat'] = (inter, cap)
                break
    
    # Filtrage des mod√®les pour lesquels les donn√©es sont disponibles
    modeles_valides = {k: v for k, v in info_modeles.items() if v['cle_feat'] is not None}
    
    if not modeles_valides:
        st.error("Aucun mod√®le ne correspond aux donn√©es disponibles.")
        return
    
    st.info(f"Mod√®les valides trouv√©s: {len(modeles_valides)}")
    
    # =============================================================================
    # S√âLECTION DES MOD√àLES √Ä ANALYSER
    # =============================================================================
    
    st.header("S√©lection des Mod√®les √† Analyser")
    
    noms_modeles = list(modeles_valides.keys())
    modeles_selectionnes = st.multiselect(
        "S√©lectionnez les mod√®les √† comparer:",
        options=noms_modeles,
        default=noms_modeles[:min(5, len(noms_modeles))],  # Max 5 par d√©faut
        help="S√©lectionnez au moins 2 mod√®les pour l'analyse de similarit√©"
    )
    
    if len(modeles_selectionnes) < 2:
        st.warning("Veuillez s√©lectionner au moins 2 mod√®les pour l'analyse.")
        return
    
    # =============================================================================
    # ANALYSE DE SIMILARIT√â PRINCIPALE
    # =============================================================================
    
    if st.button("üîç Lancer l'Analyse de Similarit√©"):
        
        # =========================================================================
        # PR√âPARATION DES DONN√âES DE TEST
        # =========================================================================
        
        donnees_test = {}
        st.write("üîß Pr√©paration des donn√©es de test...")
        
        # Pour chaque mod√®le s√©lectionn√©, pr√©parer ses donn√©es de test
        for nom_modele in modeles_selectionnes:
            cle_feat = modeles_valides[nom_modele]['cle_feat']
            if cle_feat not in feats:
                st.error(f"Cl√© {cle_feat} introuvable dans feats")
                continue
                
            df = feats[cle_feat]
            st.write(f"üìä {nom_modele.split('_')[1]}: {len(df)} √©chantillons totaux")
            
            # Division 80-20 pour train/test (on utilise seulement le test)
            split_idx = int(0.8 * len(df))
            df_test = df.iloc[split_idx:]
            st.write(f"Test: {len(df_test)} √©chantillons")
            
            # Cr√©ation des s√©quences pour ce mod√®le
            params = modeles_valides[nom_modele]['params']
            X_test, y_test = creer_sequences(df_test, params['window_size'])
            
            st.write(f"S√©quences: {X_test.shape if len(X_test) > 0 else 'Aucune'}")
            
            # Stockage des donn√©es de test si des s√©quences ont √©t√© cr√©√©es
            if len(X_test) > 0:
                donnees_test[nom_modele] = {
                    'X_test': X_test,
                    'y_test': y_test,
                    'mean_flow': df['flow'].mean(),  # Pour normaliser la MAE
                    'params': params
                }
                st.success(f"‚úÖ Donn√©es test pr√©par√©es pour {nom_modele.split('_')[1]}")
            else:
                st.error(f"‚ùå Aucune s√©quence g√©n√©r√©e pour {nom_modele.split('_')[1]}")
        
        st.write(f"Total mod√®les avec donn√©es de test: {len(donnees_test)}")
        
        if len(donnees_test) < 2:
            st.error("Pas assez de donn√©es de test valides pour l'analyse")
            return
        
        # =========================================================================
        # CALCUL DE LA MATRICE DE PERFORMANCE CROIS√âE
        # =========================================================================
        
        st.header("üìä Matrice de Similarit√©")
        
        n_modeles = len(modeles_selectionnes)
        matrice_mae = np.zeros((n_modeles, n_modeles))
        
        # Barres de progression pour l'utilisateur
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Calcul de toutes les combinaisons mod√®le_A test√© sur donn√©es_B
        for i, modele_a in enumerate(modeles_selectionnes):
            for j, modele_b in enumerate(modeles_selectionnes):
                
                # Mise √† jour de la progression
                progress = (i * n_modeles + j + 1) / (n_modeles * n_modeles)
                progress_bar.progress(progress)
                status_text.text(f"Test: {modele_a.split('_')[1]} sur donn√©es de {modele_b.split('_')[1]}")
                
                if i == j:
                    # Performance native du mod√®le (diagonale de la matrice)
                    matrice_mae[i, j] = modeles_valides[modele_a]['params']['mae_original']
                else:
                    # Test crois√©: mod√®le A test√© sur donn√©es B
                    try:
                        # V√©rification de la disponibilit√© des donn√©es de test
                        if modele_b not in donnees_test:
                            matrice_mae[i, j] = np.inf
                            continue
                            
                        data_b = donnees_test[modele_b]
                        
                        # Chargement du mod√®le A
                        model = charger_modele(
                            modeles_valides[modele_a]['chemin'],
                            modeles_valides[modele_a]['params'],
                            device
                        )
                        
                        # √âvaluation du mod√®le A sur les donn√©es B
                        mae_pct, predictions = evaluer_modele(
                            model, data_b['X_test'], data_b['y_test'], 
                            device, data_b['mean_flow']
                        )
                        
                        matrice_mae[i, j] = mae_pct
                        
                        # Nettoyage m√©moire pour √©viter l'accumulation
                        del model
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors du test de {modele_a.split('_')[1]} sur {modele_b.split('_')[1]}: {e}")
                        matrice_mae[i, j] = np.inf
        
        # Nettoyage de l'interface
        progress_bar.empty()
        status_text.empty()
        
        # =========================================================================
        # AFFICHAGE DES R√âSULTATS DE PERFORMANCE
        # =========================================================================
        
        st.success("üéØ Analyse de similarit√© termin√©e !")
        
        # Tableau r√©capitulatif des performances crois√©es
        st.subheader("üìã R√©sum√© des Performances Crois√©es")
        
        resultats_croises = []
        for i, modele_a in enumerate(modeles_selectionnes):
            for j, modele_b in enumerate(modeles_selectionnes):
                capteur_a = modeles_valides[modele_a]['capteur']
                capteur_b = modeles_valides[modele_b]['capteur']
                mae_value = matrice_mae[i, j]
                
                if i == j:
                    # Performance native
                    status = "üè† Natif"
                    diff = 0.0
                else:
                    # Performance crois√©e vs native
                    mae_native = matrice_mae[j, j]  # Performance native du mod√®le B
                    diff = mae_value - mae_native
                    
                    # Classification de la performance selon la diff√©rence avec le mod√®le natif
                    if diff <= 5.0:
                        status = "‚úÖ Excellent" if diff <= 2.0 else "üü¢ Bon"
                    elif diff <= 10.0:
                        status = "üü° Moyen"
                    else:
                        status = "üî¥ Faible"
                
                # Ajout des r√©sultats au tableau r√©capitulatif
                resultats_croises.append({
                    'Mod√®le': f"Capteur {capteur_a}",
                    'Test√© sur': f"Capteur {capteur_b}",
                    'MAE (%)': f"{mae_value:.2f}",
                    'Diff√©rence': f"{diff:+.2f}%" if i != j else "0.00%",
                    'Status': status
                })
        
        # Affichage du tableau sous forme de DataFrame interactif
        df_resultats = pd.DataFrame(resultats_croises)
        st.dataframe(df_resultats, use_container_width=True, hide_index=True)
        
        # =========================================================================
        # VISUALISATION DE LA MATRICE DE PERFORMANCE
        # =========================================================================
        
        # Cr√©ation d'une heatmap interactive avec Plotly
        df_matrice = pd.DataFrame(
            matrice_mae,
            index=[f"Capteur_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)],
            columns=[f"Donn√©es_{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
        )
        
        # Remplacement des valeurs infinies pour l'affichage
        df_matrice_display = df_matrice.replace([np.inf, -np.inf], 999)
        
        # Cr√©ation de la heatmap avec √©chelle de couleurs appropri√©e
        fig_heatmap = px.imshow(
            df_matrice_display,
            labels=dict(x="Donn√©es de test", y="Mod√®les", color="MAE %"),
            title="Matrice de Performance Crois√©e (MAE %)",
            color_continuous_scale="RdYlBu_r",  # Rouge = mauvais, Bleu = bon
            text_auto=".1f"  # Affichage des valeurs avec 1 d√©cimale
        )
        fig_heatmap.update_layout(height=500)
        
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # =========================================================================
        # ANALYSE DE SIMILARIT√â ET CLUSTERING
        # =========================================================================
        
        st.header("üîó Analyse de Regroupement")
        
        # Calcul des diff√©rences relatives entre performances crois√©es et natives
        matrice_diff = np.zeros((n_modeles, n_modeles))
        for i in range(n_modeles):
            for j in range(n_modeles):
                if i != j:
                    mae_native = matrice_mae[j, j]  # Performance native du mod√®le j
                    mae_croisee = matrice_mae[i, j]  # Performance du mod√®le i sur donn√©es j
                    diff_relative = abs(mae_croisee - mae_native)
                    matrice_diff[i, j] = diff_relative
        
        # Identification des paires de mod√®les similaires
        modeles_similaires = []
        for i in range(n_modeles):
            for j in range(i + 1, n_modeles):
                # Diff√©rence bidirectionnelle (i sur j ET j sur i)
                diff_ij = matrice_diff[i, j]  # Mod√®le i test√© sur donn√©es j
                diff_ji = matrice_diff[j, i]  # Mod√®le j test√© sur donn√©es i
                diff_moyenne = (diff_ij + diff_ji) / 2
                
                # Test du seuil de similarit√©
                if diff_moyenne <= seuil_similarite:
                    modeles_similaires.append((i, j, diff_moyenne))
        
        # =========================================================================
        # AFFICHAGE DES MOD√àLES SIMILAIRES
        # =========================================================================
        
        if modeles_similaires:
            st.success(f"üéØ Mod√®les similaires trouv√©s (seuil: {seuil_similarite}% MAE):")
            
            cols = st.columns(2)
            
            # Colonne 1: Liste des paires similaires
            with cols[0]:
                for i, j, diff in modeles_similaires:
                    nom_i = modeles_selectionnes[i]
                    nom_j = modeles_selectionnes[j]
                    
                    st.info(f"**{modeles_valides[nom_i]['capteur']} ({modeles_valides[nom_i]['intersection']})** ‚Üî "
                           f"**{modeles_valides[nom_j]['capteur']} ({modeles_valides[nom_j]['intersection']})**\n\n"
                           f"Diff√©rence moyenne: {diff:.2f}% MAE")
            
            # Colonne 2: Dendrogramme de clustering hi√©rarchique
            with cols[1]:
                st.subheader("Dendrogramme de Regroupement")
                
                # Construction de la matrice de distance sym√©trique
                distance_matrix = np.zeros((n_modeles, n_modeles))
                for i in range(n_modeles):
                    for j in range(n_modeles):
                        if i != j:
                            diff_ij = matrice_diff[i, j]
                            diff_ji = matrice_diff[j, i]
                            distance_matrix[i, j] = (diff_ij + diff_ji) / 2
                
                # Clustering hi√©rarchique avec m√©thode de Ward
                linkage_matrix = linkage(squareform(distance_matrix), method='ward')
                
                # Cr√©ation du dendrogramme
                fig, ax = plt.subplots(figsize=(10, 6))
                labels = [f"{modeles_valides[modeles_selectionnes[i]]['capteur']}" for i in range(n_modeles)]
                dendrogram(linkage_matrix, labels=labels, ax=ax, orientation='top')
                ax.set_title("Dendrogramme de Similarit√© des Mod√®les")
                ax.set_ylabel("Distance")
                plt.xticks(rotation=45)
                st.pyplot(fig)
        
        else:
            st.warning(f"Aucun mod√®le similaire trouv√© avec le seuil de {seuil_similarite}% MAE.")
        
        # =========================================================================
        # G√âN√âRATION DES RECOMMANDATIONS
        # =========================================================================
        
        st.header("üí° Recommandations")
        
        if modeles_similaires:
            st.markdown("### Strat√©gies de Consolidation Possibles:")
            
            # Algorithme de regroupement des mod√®les similaires
            groupes = []
            modeles_assignes = set()
            
            # Premi√®re passe: cr√©er des groupes initiaux
            for i, j, diff in modeles_similaires:
                if i not in modeles_assignes and j not in modeles_assignes:
                    groupes.append([i, j])
                    modeles_assignes.update([i, j])
                elif i in modeles_assignes:
                    # Ajouter j au groupe contenant i
                    for groupe in groupes:
                        if i in groupe and j not in modeles_assignes:
                            groupe.append(j)
                            modeles_assignes.add(j)
                            break
                elif j in modeles_assignes:
                    # Ajouter i au groupe contenant j
                    for groupe in groupes:
                        if j in groupe and i not in modeles_assignes:
                            groupe.append(i)
                            modeles_assignes.add(i)
                            break
            
            # Affichage des groupes identifi√©s
            for idx, groupe in enumerate(groupes, 1):
                st.success(f"**Groupe {idx}**: Peut utiliser un mod√®le commun")
                for model_idx in groupe:
                    nom = modeles_selectionnes[model_idx]
                    capteur = modeles_valides[nom]['capteur']
                    intersection = modeles_valides[nom]['intersection']
                    mae_orig = modeles_valides[nom]['params']['mae_original']
                    st.write(f"- {capteur} ({intersection}) - MAE original: {mae_orig}%")
            
            # Calcul des m√©triques de r√©duction
            reduction_modeles = len(modeles_similaires)
            reduction_pct = (reduction_modeles / len(modeles_selectionnes)) * 100
            
            st.info(f"**R√©duction potentielle**: {reduction_modeles} mod√®les en moins "
                   f"({reduction_pct:.1f}% de r√©duction)")
        
        else:
            st.markdown("### Recommandations:")
            st.write("- Tous les mod√®les semblent sp√©cifiques √† leur capteur")
            st.write("- Consid√©rez d'assouplir le seuil de similarit√© si appropri√©")
            st.write("- Analysez les caract√©ristiques des capteurs pour identifier des groupes logiques")
        
        # =========================================================================
        # TABLEAU D√âTAILL√â DES R√âSULTATS
        # =========================================================================
        
        st.header("üìã R√©sultats D√©taill√©s")
        
        # Compilation des informations d√©taill√©es de chaque mod√®le
        resultats_details = []
        for i, nom_modele in enumerate(modeles_selectionnes):
            info = modeles_valides[nom_modele]
            resultats_details.append({
                'Mod√®le': f"Mod√®le_{i+1}",
                'Capteur': info['capteur'],
                'Intersection': info['intersection'],
                'MAE Original (%)': info['params']['mae_original'],
                'Hidden Size': info['params']['hidden_size'],
                'Layers': info['params']['num_layers'],
                'Dropout': info['params']['dropout'],
                'Window Size': info['params']['window_size']
            })
        
        # Affichage du tableau r√©capitulatif
        df_details = pd.DataFrame(resultats_details)
        st.dataframe(df_details, use_container_width=True)

# =============================================================================
# POINT D'ENTR√âE DE L'APPLICATION
# =============================================================================

if __name__ == "__main__":
    main()
